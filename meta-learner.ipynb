{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from aeon.visualisation import plot_series\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from all_functions import *\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_each_point_error(path, val_date):\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    \n",
    "    df_filtered = df[df['test_range'] <= val_date].copy()\n",
    "\n",
    "    df_filtered = df_filtered.iloc[::-1]\n",
    "    \n",
    "    error_series_concatenated = []\n",
    "    for _, row in df_filtered.iterrows():\n",
    "        error_series_str = row['error_series']\n",
    "        error_list = ast.literal_eval(error_series_str)\n",
    "        error_series_concatenated.append(error_list)\n",
    "    return error_series_concatenated\n",
    "\n",
    "\n",
    "def get_all_error_series(path, val_date):\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    \n",
    "    df_filtered = df[df['test_range'] <= val_date].copy()\n",
    "\n",
    "    df_filtered = df_filtered.iloc[::-1]\n",
    "    \n",
    "    error_series_concatenated = []\n",
    "    for _, row in df_filtered.iterrows():\n",
    "        error_series_str = row['error_series']\n",
    "        error_list = ast.literal_eval(error_series_str)\n",
    "        error_series_concatenated.extend(error_list)\n",
    "    \n",
    "    return error_series_concatenated\n",
    "\n",
    "def generate_index(start_date, end_date):\n",
    "    end_date_dt = pd.to_datetime(end_date)\n",
    "    \n",
    "    start_date_dt = pd.to_datetime(start_date)\n",
    "    \n",
    "    index = pd.period_range(start=start_date_dt, end=end_date_dt, freq='M')\n",
    "\n",
    "    return index\n",
    "\n",
    "def get_test_real(series, start_date, end_date):\n",
    "    start_period = pd.to_datetime(start_date).to_period('M')\n",
    "    end_period = (pd.to_datetime(end_date))\n",
    "    \n",
    "    filtered_series = series.loc[start_period:end_period]\n",
    "\n",
    "    return filtered_series\n",
    "\n",
    "def get_train_real(series, start_date):\n",
    "    start_period = pd.to_datetime(start_date).to_period('M')\n",
    "    \n",
    "    filtered_series = series[series.index < start_period]\n",
    "\n",
    "    return filtered_series\n",
    "\n",
    "def preds_recursive_meta(example, model, horizon):\n",
    "  preds = []\n",
    "  for i in range(horizon):\n",
    "    pred = model.predict(example)[0]\n",
    "    preds.append(pred)\n",
    "\n",
    "    example = example[:,1:]\n",
    "\n",
    "    example = np.append(example, pred)\n",
    "    example = example.reshape(1,-1)\n",
    "  return preds\n",
    "\n",
    "def get_preds_hybrid(path, test_date, start_index):\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    results = {}\n",
    "    filtered_df = df[df['test_range'] == test_date]\n",
    "    columns_p1_to_p12 = filtered_df.loc[:, 'P1':'P12']\n",
    "    values_list = columns_p1_to_p12.values.flatten().tolist()     \n",
    "    results = pd.Series(values_list, index=start_index)\n",
    "    return results\n",
    "\n",
    "\n",
    "def save_csv(nome, csv_file, uf, derivado, models, series, test, preds, horizon=12, window=12):\n",
    "    y_baseline = series[-horizon*2:-horizon].values\n",
    "    rmse_result = rmse(test, preds)\n",
    "    mape_result = mape(test, preds)\n",
    "    pocid_result = pocid(test, preds)\n",
    "    pbe_result = pbe(test, preds)\n",
    "    mcpm_result = mcpm(rmse_result, mape_result, pocid_result)\n",
    "    mase_result = mase(test, preds, y_baseline)\n",
    "\n",
    "    df_result = pd.DataFrame({'DATA': nome, 'UF': uf, 'PRODUCT': derivado, 'MODEL':  f\"{'_'.join(models)}\", 'PARAMS': str({}), 'WINDOW': window, 'HORIZON': horizon,  \n",
    "                                            'RMSE': rmse_result, 'MAPE': mape_result, 'POCID': pocid_result, 'PBE': pbe_result, 'MASE': mase_result,\n",
    "                                            'P1': preds[0], 'P2': preds[1], 'P3': preds[2], 'P4': preds[3], 'P5': preds[4],\n",
    "                                            'P6': preds[5], 'P7': preds[6], 'P8': preds[7], 'P9': preds[8], 'P10': preds[9],\n",
    "                                            'P11': preds[10], 'P12': preds[11]\n",
    "                                            }, index=[0])\n",
    "    df_result.to_csv(csv_file, sep=';', mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_learner_erro(meta_model, test_date, val_date):\n",
    "    transformations = ['normal', 'deseasonal', 'log']\n",
    "    models = [\"knn\", \"rf\", \"deepar\", \"svr\", \"catboost\", \"arima\"]\n",
    "\n",
    "    horizon = 12\n",
    "    window = 12\n",
    "    dirs = [\n",
    "        '../datasets/venda/mensal/uf/gasolinac/',\n",
    "        '../datasets/venda/mensal/uf/etanolhidratado/',\n",
    "        '../datasets/venda/mensal/uf/glp/',\n",
    "        '../datasets/venda/mensal/uf/oleodiesel/',\n",
    "    ]\n",
    "    colunas = ['DATA', 'UF', 'PRODUCT', 'MODEL', 'PARAMS', 'WINDOW', 'HORIZON', 'RMSE', 'MAPE', 'POCID', 'PBE', 'MASE',\n",
    "           'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12',\n",
    "           ]\n",
    "    start_date, end_date = test_date.split('_')\n",
    "    test_index = generate_index(start_date, end_date)\n",
    "\n",
    "  \n",
    "    for directory in dirs:\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.csv'):\n",
    "                uf = file.split(\"_\")[1].upper()\n",
    "                derivado = file.split(\"_\")[2].split(\".\")[0]\n",
    "                full_path = os.path.join(directory, file)\n",
    "                series = read_series(full_path)\n",
    "                test_real = get_test_real(series, start_date, end_date)\n",
    "                preds_start = []\n",
    "                for model in models:\n",
    "                    results_file = f'./error_preds/{model}/{derivado}/meta_{meta_model}/{test_date}'\n",
    "                    for transform in transformations:\n",
    "                        error_serie = get_all_error_series(\n",
    "                            f'./results/{model}/{derivado}/{transform}/transform_{uf}.csv', \n",
    "                            val_date\n",
    "                        )\n",
    "\n",
    "                        test_error = get_error_series(f'./results/{model}/{derivado}/{transform}/transform_{uf}.csv', test_date)\n",
    "\n",
    "                        #condicao para retirar o ponto de partida (X_test) do train\n",
    "                        preds_start = error_serie[-12:]\n",
    "                        error_serie = error_serie[:-12]\n",
    "                        \n",
    "                        data = rolling_window(error_serie, 12)\n",
    "                            \n",
    "                        data = data.reset_index(drop=True)\n",
    "                        data.columns = data.columns.astype(str)\n",
    "                        X_train = data.drop(columns=['12'])\n",
    "                        y_train = data[['12']].squeeze()\n",
    "\n",
    "                        start_norm = znorm(preds_start)\n",
    "                        X_test = np.array([start_norm])\n",
    "\n",
    "                        rg = RandomForestRegressor()\n",
    "                        rg.fit(X_train, y_train)\n",
    "                        predictions = preds_recursive_meta(X_test, rg, horizon)\n",
    "                        preds_real = znorm_reverse(pd.Series(predictions), np.mean(preds_start), np.std(preds_start))\n",
    "\n",
    "                        preds_target = get_preds_hybrid(f'./results/{model}/{derivado}/{transform}/transform_{uf}.csv', test_date, test_index)\n",
    "                        # somados = preds_target + preds_real.values\n",
    "\n",
    "                        path_derivado = results_file\n",
    "                        csv_file = path_derivado + f\"/transform_{uf.upper()}.csv\"\n",
    "                        os.makedirs(path_derivado, exist_ok=True)\n",
    "                        if not os.path.exists(csv_file):\n",
    "                            pd.DataFrame(columns=colunas).to_csv(csv_file, sep=';', index=False)\n",
    "                            \n",
    "                        # save_csv(transform, csv_file, uf, derivado, models, series, test_real, somados, horizon, window)\n",
    "                        error_complete = error_serie\n",
    "                        error_complete.extend(test_error)\n",
    "                        save_csv(transform, csv_file, uf, derivado, [model], pd.Series(error_complete), test_error, preds_real.values, horizon, window)\n",
    "\n",
    "val_date = '2022-03_2023-02'\n",
    "test_date = '2023-03_2024-02'\n",
    "meta_model = \"rf\"\n",
    "meta_learner_erro(meta_model, test_date, val_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
