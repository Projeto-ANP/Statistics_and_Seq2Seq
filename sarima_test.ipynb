{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anp/anaconda3/lib/python3.11/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U aeon\n",
    "#!pip install aeon[all_extras]\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from aeon.visualisation import plot_series\n",
    "from all_functions import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from aeon.transformations.detrend import STLTransformer\n",
    "import ast\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import os\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "def convert_to_list(series_str):\n",
    "    return eval(series_str)\n",
    "\n",
    "def read_tsf(file_path):\n",
    "    with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    metadata = []\n",
    "    series = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith('@') or line.startswith('#'):\n",
    "            metadata.append(line.strip())\n",
    "        else:\n",
    "            series.append(line.strip())\n",
    "\n",
    "    formatted_data = []\n",
    "\n",
    "    # Processar cada linha de série\n",
    "    for entry in series:\n",
    "        dataset_name, start_date, series_values = entry.split(':', 2)\n",
    "        start_date = start_date.strip()\n",
    "        series_list = [float(value) for value in series_values.split(',')]\n",
    "        \n",
    "        # Adicionar aos dados formatados\n",
    "        formatted_data.append({\n",
    "            'dataset': dataset_name,\n",
    "            'start_date': start_date,\n",
    "            'series': series_list\n",
    "        })\n",
    "        \n",
    "    series_data = pd.DataFrame(formatted_data)\n",
    "\n",
    "\n",
    "    return metadata, series_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Função para calcular os valores de SMAPE\n",
    "def calculate_smape(forecasts, test_set):\n",
    "    smape = 2 * np.abs(forecasts - test_set) / (np.abs(forecasts) + np.abs(test_set))\n",
    "    smape_per_series = np.nanmean(smape, axis=1)  # Média por série\n",
    "    return smape_per_series\n",
    "\n",
    "# Função para calcular os valores de mSMAPE\n",
    "def calculate_msmape(forecasts, test_set):\n",
    "    epsilon = 0.1\n",
    "    comparator = np.full(test_set.shape, 0.5 + epsilon)\n",
    "    sum_values = np.maximum(comparator, (np.abs(forecasts) + np.abs(test_set) + epsilon))\n",
    "    smape = 2 * np.abs(forecasts - test_set) / sum_values\n",
    "    msmape_per_series = np.nanmean(smape, axis=1)\n",
    "    return msmape_per_series\n",
    "\n",
    "# Função para calcular os valores de MASE\n",
    "def calculate_mase(forecasts, test_set, training_set, seasonality):\n",
    "    mase_per_series = []\n",
    "    \n",
    "    for k in range(forecasts.shape[0]):\n",
    "        te = test_set[k, ~np.isnan(test_set[k, :])]\n",
    "        tr = training_set[k][~np.isnan(training_set[k])]\n",
    "        f = forecasts[k, ~np.isnan(forecasts[k, :])]\n",
    "        \n",
    "        # Cálculo de MASE\n",
    "        mase = MASE(te, f, np.mean(np.abs(np.diff(tr, n=1, axis=0, prepend=tr[0]))))\n",
    "        \n",
    "        if np.isnan(mase):\n",
    "            mase = MASE(te, f, np.mean(np.abs(np.diff(tr, n=1, axis=0, prepend=tr[0]))))\n",
    "        \n",
    "        mase_per_series.append(mase)\n",
    "\n",
    "    return np.array(mase_per_series)\n",
    "\n",
    "# Função para calcular os valores de MAE\n",
    "def calculate_mae(forecasts, test_set):\n",
    "    mae = np.abs(forecasts - test_set)\n",
    "    mae_per_series = np.nanmean(mae, axis=1)\n",
    "    return mae_per_series\n",
    "\n",
    "# Função para calcular os valores de RMSE\n",
    "def calculate_rmse(forecasts, test_set):\n",
    "    squared_errors = (forecasts - test_set) ** 2\n",
    "    rmse_per_series = np.sqrt(np.nanmean(squared_errors, axis=1))\n",
    "    return rmse_per_series\n",
    "\n",
    "# Função para fornecer um resumo das métricas de erro\n",
    "def calculate_errors(forecasts, test_set, training_set, seasonality, output_file_name):\n",
    "    smape_per_series = calculate_smape(forecasts, test_set)\n",
    "    msmape_per_series = calculate_msmape(forecasts, test_set)\n",
    "    mase_per_series = calculate_mase(forecasts, test_set, training_set, seasonality)\n",
    "    mae_per_series = calculate_mae(forecasts, test_set)\n",
    "    rmse_per_series = calculate_rmse(forecasts, test_set)\n",
    "\n",
    "    metrics = {\n",
    "        \"Mean SMAPE\": np.nanmean(smape_per_series),\n",
    "        \"Median SMAPE\": np.nanmedian(smape_per_series),\n",
    "        \"Mean mSMAPE\": np.nanmean(msmape_per_series),\n",
    "        \"Median mSMAPE\": np.nanmedian(msmape_per_series),\n",
    "        \"Mean MASE\": np.nanmean(mase_per_series),\n",
    "        \"Median MASE\": np.nanmedian(mase_per_series),\n",
    "        \"Mean MAE\": np.nanmean(mae_per_series),\n",
    "        \"Median MAE\": np.nanmedian(mae_per_series),\n",
    "        \"Mean RMSE\": np.nanmean(rmse_per_series),\n",
    "        \"Median RMSE\": np.nanmedian(rmse_per_series),\n",
    "    }\n",
    "\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # Escrevendo as métricas em arquivos\n",
    "    np.savetxt(f\"{output_file_name}_smape.txt\", smape_per_series, delimiter=\",\")\n",
    "    np.savetxt(f\"{output_file_name}_msmape.txt\", msmape_per_series, delimiter=\",\")\n",
    "    np.savetxt(f\"{output_file_name}_mase.txt\", mase_per_series, delimiter=\",\")\n",
    "    np.savetxt(f\"{output_file_name}_mae.txt\", mae_per_series, delimiter=\",\")\n",
    "    np.savetxt(f\"{output_file_name}_rmse.txt\", rmse_per_series, delimiter=\",\")\n",
    "    \n",
    "    with open(f\"{output_file_name}.txt\", \"w\") as f:\n",
    "        for key, value in metrics.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "# Função auxiliar para calcular MASE\n",
    "def MASE(actual, forecast, training_mean):\n",
    "    return np.mean(np.abs(actual - forecast)) / training_mean if training_mean != 0 else np.nan\n",
    "\n",
    "\n",
    "def morlet_wavelet(f, t, w=5):\n",
    "    \"\"\"Gera a wavelet de Morlet.\"\"\"\n",
    "    if f == 0:\n",
    "        return np.zeros_like(t)\n",
    "    return np.exp(1j * 2 * np.pi * f * t) * np.exp(-t ** 2 / (2 * (w / (2 * np.pi * f)) ** 2))\n",
    "\n",
    "def apply_kernel(X, num_kernels, lengths, dilations, paddings, biases):\n",
    "    X = np.array(X)\n",
    "    input_length = len(X)\n",
    "\n",
    "    features = np.zeros((input_length, num_kernels))\n",
    "\n",
    "    for k in range(num_kernels):\n",
    "        length = lengths[k]\n",
    "        padding = paddings[k]\n",
    "        bias = biases[k]\n",
    "        dilation = dilations[k]\n",
    "\n",
    "        end = (input_length + padding) - ((length - 1) * dilation)\n",
    "\n",
    "        for i in range(-padding, end):\n",
    "            _sum = bias\n",
    "            index = i\n",
    "\n",
    "            for j in range(length):\n",
    "                wavelet_index = index + j * dilation\n",
    "                if 0 <= wavelet_index < input_length:\n",
    "                    frequency = 1 / (length / 2)\n",
    "                    wavelet_value = morlet_wavelet(frequency, j / length)\n",
    "                    _sum += wavelet_value.real * X[wavelet_index]\n",
    "            \n",
    "            if i + padding >= 0:\n",
    "                features[i + padding, k] = _sum\n",
    "\n",
    "    return features, np.sum(features > 0)\n",
    "\n",
    "def features_target(series, window):\n",
    "    data = []\n",
    "\n",
    "    num_kernels = 1\n",
    "    # lengths = np.array([3, 5, 7])\n",
    "    # dilations = np.array([1, 2, 1])\n",
    "    # paddings = np.array([1, 0, 2])\n",
    "    # biases = np.random.uniform(-1, 1, size=num_kernels)\n",
    "\n",
    "    weights, lengths, biases, dilations, paddings = generate_kernels(len(series), num_kernels)\n",
    "    \n",
    "    for i in range(len(series) - window):\n",
    "      example = np.array(series[i:i+window])\n",
    "      target_value = series[i+window]\n",
    "      features, ppv_count = apply_kernel(example, num_kernels, lengths, dilations, paddings, biases)\n",
    "      data.append(np.concatenate((features.flatten(), [target_value])))\n",
    "\n",
    "      df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_kernels(input_length, num_kernels):\n",
    "\n",
    "    candidate_lengths = np.array((7, 9, 11), dtype = np.int32)\n",
    "    lengths = np.random.choice(candidate_lengths, num_kernels)\n",
    "\n",
    "    weights = np.zeros(lengths.sum(), dtype = np.float64)\n",
    "    biases = np.zeros(num_kernels, dtype = np.float64)\n",
    "    dilations = np.zeros(num_kernels, dtype = np.int32)\n",
    "    paddings = np.zeros(num_kernels, dtype = np.int32)\n",
    "\n",
    "    a1 = 0\n",
    "\n",
    "    for i in range(num_kernels):\n",
    "        _length = lengths[i]\n",
    "\n",
    "        _weights = np.random.normal(0, 1, _length)\n",
    "\n",
    "        b1 = a1 + _length\n",
    "        weights[a1:b1] = _weights - _weights.mean()\n",
    "\n",
    "        biases[i] = np.random.uniform(-1, 1)\n",
    "        dilation = 2 ** np.random.uniform(0, np.log2((input_length - 1) / (_length - 1)))\n",
    "        dilation = np.int32(dilation)\n",
    "        dilations[i] = dilation\n",
    "\n",
    "        padding = ((_length - 1) * dilation) // 2 if np.random.randint(2) == 1 else 0\n",
    "        paddings[i] = padding\n",
    "\n",
    "        a1 = b1\n",
    "\n",
    "    return weights, lengths, biases, dilations, paddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_even(n):\n",
    "    return n + (n % 2)\n",
    "\n",
    "\n",
    "def recursive_rocket2(X_test, model, feats, horizon):\n",
    "  # example é composto pelas últimas observações vistas\n",
    "  # na prática, é o primeiro exemplo do conjunto de teste\n",
    "  num_kernels = 1\n",
    "  # lengths = np.array([3, 5, 7])\n",
    "  # dilations = np.array([1, 2, 1])\n",
    "  # paddings = np.array([1, 0, 2])\n",
    "  # biases = np.random.uniform(-1, 1, size=num_kernels)\n",
    "  weights, lengths, biases, dilations, paddings = generate_kernels(len(feats), num_kernels)\n",
    "  example = X_test.iloc[0].values.reshape(1,-1)\n",
    "  preds = []\n",
    "  for i in range(horizon):\n",
    "    pred = model.predict(example)[0]\n",
    "    preds.append(pred)\n",
    "    feats.append(pred)\n",
    "    feats = feats[1:]\n",
    "\n",
    "   # example = example[:,2:]\n",
    "\n",
    "    # print(example)\n",
    "    transformed_feats, _ = apply_kernel(feats, num_kernels, lengths, dilations, paddings, biases)\n",
    "    # example = np.append(example, feats)\n",
    "    # example = example.reshape(1,-1)\n",
    "    example = transformed_feats.flatten()\n",
    "    example = example.reshape(1,-1)\n",
    "  return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata, series_data = read_tsf('../m4/m4_monthly_dataset.tsf')\n",
    "for meta in metadata:\n",
    "    if '@horizon' in meta:\n",
    "        h = meta[9:]\n",
    "\n",
    "int(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1494.8910740127774\n",
      "1\n",
      "817.8661397577401\n",
      "2\n",
      "680.8954137470688\n",
      "3\n",
      "714.132136595855\n",
      "4\n",
      "658.6774947138101\n",
      "5\n",
      "609.3420837100128\n",
      "6\n",
      "768.1889408436191\n",
      "7\n",
      "1024.0984424778223\n",
      "8\n",
      "1187.911312869587\n",
      "Index: 9 | Input X contains NaN.\n",
      "RandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "947\n",
      "10\n",
      "1074.0345505552377\n",
      "11\n",
      "978.7130392238737\n",
      "12\n",
      "919.4363892484339\n",
      "13\n",
      "862.3273611757321\n",
      "14\n",
      "878.9420658958499\n",
      "15\n",
      "926.9904190964622\n",
      "16\n",
      "889.5851604315649\n",
      "17\n",
      "853.9809343595925\n",
      "18\n",
      "897.4175648251719\n",
      "19\n",
      "884.2071498269772\n",
      "20\n",
      "883.8431280292955\n",
      "21\n",
      "872.2149435291709\n",
      "22\n",
      "837.4402704971974\n",
      "23\n",
      "987.2381969492793\n",
      "24\n",
      "1001.1503355751298\n",
      "25\n",
      "1037.4172598031405\n",
      "26\n",
      "1044.1926208161176\n",
      "27\n",
      "1097.5108862960626\n",
      "28\n",
      "1084.2522867631528\n",
      "29\n",
      "1101.3316692977467\n",
      "30\n",
      "1087.3751844909702\n",
      "31\n",
      "1131.773058517996\n",
      "32\n",
      "1121.6177677800533\n",
      "33\n",
      "1111.8160931905577\n",
      "34\n",
      "1100.4815563088812\n",
      "35\n",
      "1148.5615899452127\n",
      "36\n",
      "1117.4407648458039\n",
      "37\n",
      "1090.047582754969\n",
      "38\n",
      "1063.8359592777433\n",
      "39\n",
      "1039.064777492869\n",
      "40\n",
      "1016.3555465862203\n",
      "41\n",
      "994.8262773396096\n",
      "42\n",
      "974.284578255729\n",
      "43\n",
      "953.9572641244788\n",
      "44\n",
      "934.957027533303\n",
      "45\n",
      "919.0120344253698\n",
      "46\n",
      "902.4484508028669\n",
      "47\n",
      "886.9140410734868\n",
      "48\n",
      "870.7225793636244\n",
      "49\n",
      "855.0763038581043\n",
      "50\n",
      "841.2658735033574\n",
      "51\n",
      "829.6574654557339\n",
      "52\n",
      "819.4157245112686\n",
      "53\n",
      "805.2984178299884\n",
      "54\n",
      "800.4475446350126\n",
      "55\n",
      "806.0582826774352\n",
      "56\n",
      "806.3953726110741\n",
      "57\n",
      "798.2554953821457\n",
      "58\n",
      "795.1287348533191\n",
      "59\n",
      "788.5989388417231\n",
      "60\n",
      "780.7234237983944\n",
      "61\n",
      "770.9086978365792\n",
      "62\n",
      "763.0468741455466\n",
      "63\n",
      "767.3934347059761\n",
      "64\n",
      "775.3559812484001\n",
      "65\n",
      "767.8295180518567\n",
      "66\n",
      "768.4770401534746\n",
      "67\n",
      "757.569870574762\n",
      "68\n",
      "747.2442709258657\n",
      "69\n",
      "736.911955471043\n",
      "70\n",
      "727.1973677201386\n",
      "71\n",
      "717.8136874037783\n",
      "72\n",
      "708.7048998212194\n",
      "73\n",
      "715.8469187773456\n",
      "74\n",
      "718.4603561051848\n",
      "75\n",
      "714.3113156486413\n",
      "76\n",
      "718.1027510409339\n",
      "77\n",
      "720.6596515343367\n",
      "78\n",
      "718.0069830510273\n",
      "79\n",
      "715.6861632804888\n",
      "80\n",
      "715.8829101773647\n",
      "81\n",
      "707.1692152772758\n",
      "82\n",
      "700.8758061395074\n",
      "83\n",
      "694.1562205698935\n",
      "84\n",
      "691.7980207532344\n",
      "85\n",
      "689.5133617627174\n",
      "86\n",
      "681.5460608571764\n",
      "87\n",
      "675.215141189218\n",
      "88\n",
      "668.9452411947991\n",
      "89\n",
      "661.6712978270615\n",
      "90\n",
      "656.8716676899345\n",
      "91\n",
      "672.6968071904462\n",
      "92\n",
      "665.6812679381925\n",
      "93\n",
      "661.1732695817756\n",
      "94\n",
      "658.1731459634866\n",
      "95\n",
      "653.3155621656548\n",
      "96\n",
      "646.8427223114253\n",
      "97\n",
      "640.5254494556659\n",
      "98\n",
      "637.8377678474666\n",
      "99\n",
      "634.5887443255348\n",
      "100\n",
      "631.3998382269484\n",
      "101\n",
      "627.1754088846171\n",
      "102\n",
      "622.4875764294779\n",
      "103\n",
      "617.2001442665475\n",
      "104\n",
      "611.8439315705726\n",
      "105\n",
      "606.1343823685701\n",
      "106\n",
      "608.9216119713934\n",
      "107\n",
      "604.0009043897134\n",
      "108\n",
      "599.1470217503237\n",
      "109\n",
      "596.0272991514764\n",
      "110\n",
      "590.7061469821324\n",
      "111\n",
      "586.897218863576\n",
      "112\n",
      "581.9680621749048\n",
      "113\n",
      "578.2849353191607\n",
      "114\n",
      "575.1491307064639\n",
      "115\n",
      "575.599136191916\n",
      "116\n",
      "572.6914477543758\n",
      "117\n",
      "567.9587752370119\n",
      "118\n",
      "564.7042372575708\n",
      "119\n",
      "562.3454163754652\n",
      "120\n",
      "559.7558233191254\n",
      "121\n",
      "555.3514927716897\n",
      "122\n",
      "551.0073759887433\n",
      "123\n",
      "548.7174917862077\n",
      "124\n",
      "546.0828027650456\n",
      "125\n",
      "543.8252281220658\n",
      "126\n",
      "541.076845682385\n",
      "127\n",
      "537.6914781813282\n",
      "128\n",
      "534.1515648229536\n",
      "129\n",
      "530.3543070627802\n",
      "130\n",
      "526.3906855864328\n",
      "131\n",
      "528.9255590413122\n",
      "132\n",
      "526.1901251992149\n",
      "133\n",
      "523.9543654872909\n",
      "134\n",
      "522.7506955992167\n",
      "135\n",
      "521.893260777546\n",
      "136\n",
      "519.050750500441\n",
      "137\n",
      "515.5152685910809\n",
      "138\n",
      "512.4631462228542\n",
      "139\n",
      "509.69035100001435\n",
      "140\n",
      "511.77819048329434\n",
      "141\n",
      "509.2971029520107\n",
      "142\n",
      "506.6044948366235\n",
      "143\n",
      "504.40500921413866\n",
      "144\n",
      "513.0673578676401\n",
      "145\n",
      "510.86557887228014\n",
      "146\n",
      "507.42618568297075\n",
      "147\n",
      "504.06757504166023\n",
      "148\n",
      "503.44532408710023\n",
      "149\n",
      "501.6952047754199\n",
      "150\n",
      "499.8534815997751\n",
      "151\n",
      "497.54237317410855\n",
      "152\n",
      "494.94581774998596\n",
      "153\n",
      "495.7502090334875\n",
      "154\n",
      "493.0125877716835\n",
      "155\n",
      "490.2310147552027\n",
      "156\n",
      "487.1404591749598\n",
      "157\n",
      "489.36732524075524\n",
      "158\n",
      "487.1321375788996\n",
      "159\n",
      "484.9509147530493\n",
      "160\n",
      "484.65414042648916\n",
      "161\n",
      "482.8558311972785\n",
      "162\n",
      "480.1071506781887\n",
      "163\n",
      "478.5833394472055\n",
      "164\n",
      "476.5948331192885\n",
      "165\n",
      "474.19524138284316\n",
      "166\n",
      "471.842841240313\n",
      "167\n",
      "470.0087997885055\n",
      "168\n",
      "467.6274781955354\n",
      "169\n",
      "465.59021883165576\n",
      "170\n",
      "463.765048125999\n",
      "171\n",
      "461.6316419351249\n",
      "172\n",
      "460.904294035648\n",
      "173\n",
      "458.3954015959933\n",
      "174\n",
      "456.27883591866294\n",
      "175\n",
      "454.00792707868345\n",
      "176\n",
      "453.0978088966562\n",
      "177\n",
      "451.2024184629415\n",
      "178\n",
      "448.84984232455196\n",
      "179\n",
      "447.2423249586627\n",
      "180\n",
      "445.66859435127157\n",
      "181\n",
      "444.00281343948956\n",
      "182\n",
      "442.2911408108434\n",
      "183\n",
      "440.32992740755117\n",
      "184\n",
      "438.3522996225007\n",
      "185\n",
      "436.1380982998097\n",
      "186\n",
      "434.1562693280073\n",
      "187\n",
      "432.97904497202995\n",
      "188\n",
      "431.7171511980653\n",
      "189\n",
      "429.6941317222077\n",
      "190\n",
      "430.05463712359796\n",
      "191\n",
      "428.5572922940215\n",
      "192\n",
      "426.9522394556797\n",
      "193\n",
      "424.9901569215005\n",
      "194\n",
      "423.69636976940353\n",
      "195\n",
      "429.4300976935183\n",
      "196\n",
      "429.47610604284847\n",
      "197\n",
      "427.80083252855184\n",
      "198\n",
      "426.22976261537207\n",
      "199\n",
      "425.0377928553738\n",
      "200\n",
      "424.06177649203323\n",
      "201\n",
      "424.6348214604704\n",
      "202\n",
      "428.6677098727256\n",
      "203\n",
      "427.17258747414155\n",
      "204\n",
      "434.8146145502871\n",
      "205\n",
      "434.0069661523841\n",
      "206\n",
      "459.3745206062415\n",
      "207\n",
      "470.0907863332297\n",
      "Index: 208 | Input X contains NaN.\n",
      "RandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "947\n",
      "209\n",
      "474.8974207164217\n",
      "210\n",
      "485.2941446165616\n",
      "211\n",
      "485.2333274373542\n",
      "212\n",
      "484.26557390463654\n",
      "213\n",
      "482.418189294937\n",
      "214\n",
      "480.6019304613161\n",
      "215\n",
      "478.8268016586592\n",
      "216\n",
      "477.71099832544786\n",
      "217\n",
      "477.30301228807446\n",
      "218\n",
      "475.1641572681969\n",
      "219\n",
      "473.03688157840315\n",
      "220\n",
      "474.30631654173465\n",
      "221\n",
      "475.13506013665585\n",
      "222\n",
      "475.4709728000644\n",
      "223\n",
      "474.76055169162055\n",
      "224\n",
      "473.66299768105415\n",
      "225\n",
      "474.83400675666496\n",
      "226\n",
      "473.5374239754996\n",
      "227\n",
      "472.37240580083784\n",
      "228\n",
      "470.72087725928094\n",
      "229\n",
      "471.5106652456019\n",
      "230\n",
      "471.7669629146205\n",
      "231\n",
      "472.2740929755058\n",
      "232\n",
      "471.2681362725793\n",
      "233\n",
      "470.62813277658825\n",
      "234\n",
      "469.89250197264334\n",
      "235\n",
      "469.7744923623872\n",
      "236\n",
      "468.60993966884325\n",
      "237\n",
      "467.79368520391347\n",
      "238\n",
      "469.16546221571974\n",
      "239\n",
      "470.3008959921519\n",
      "240\n",
      "469.27944014345775\n",
      "241\n",
      "468.1507834171237\n",
      "242\n",
      "473.1237946518968\n",
      "243\n",
      "472.7328168604962\n",
      "244\n",
      "472.0181459406302\n",
      "245\n",
      "471.15812365792914\n",
      "246\n",
      "475.61037776274594\n",
      "247\n",
      "476.3681636940636\n",
      "248\n",
      "485.3704991585991\n",
      "249\n",
      "483.849663145709\n",
      "250\n",
      "483.2110024898618\n",
      "251\n",
      "481.81958521912253\n",
      "252\n",
      "481.5629626780306\n",
      "253\n",
      "480.46984298551007\n",
      "254\n",
      "478.7613993475563\n",
      "255\n",
      "478.4153501560239\n",
      "256\n",
      "476.629921031821\n",
      "257\n",
      "475.2794051417902\n",
      "258\n",
      "475.5762862725017\n",
      "259\n",
      "474.75423089849505\n",
      "260\n",
      "473.16388558797496\n",
      "261\n",
      "471.3815894483829\n",
      "262\n",
      "471.846434526904\n",
      "263\n",
      "471.5844795972378\n",
      "264\n",
      "471.03734626715266\n",
      "265\n",
      "470.6662360548705\n",
      "266\n",
      "472.15688800420696\n",
      "267\n",
      "471.0527095343749\n",
      "268\n",
      "469.9751089279407\n",
      "269\n",
      "470.6424528908506\n",
      "270\n",
      "471.98285230397875\n",
      "271\n",
      "470.381240044434\n",
      "272\n",
      "470.05167587609935\n",
      "273\n",
      "468.84037642217544\n",
      "274\n",
      "472.3955507245728\n",
      "275\n",
      "472.5304802363318\n",
      "276\n",
      "470.98724038013955\n",
      "277\n",
      "469.87961496506625\n",
      "278\n",
      "468.7663078646628\n",
      "279\n",
      "467.39512181170693\n",
      "280\n",
      "466.1602560186843\n",
      "281\n",
      "464.6498761274891\n",
      "282\n",
      "463.03966963033787\n",
      "283\n",
      "461.4924938258655\n",
      "284\n",
      "459.9491553434321\n",
      "285\n",
      "459.4901281679705\n",
      "286\n",
      "458.4040856237997\n",
      "287\n",
      "457.1001620199394\n",
      "288\n",
      "456.3574082032355\n",
      "289\n",
      "459.5406147964843\n",
      "290\n",
      "461.6776853999334\n",
      "291\n",
      "466.49065362641556\n",
      "292\n",
      "466.9615942479365\n",
      "293\n",
      "466.4111884350653\n",
      "294\n",
      "467.64366884368803\n",
      "295\n",
      "467.62854131444124\n",
      "296\n",
      "468.43959081325784\n",
      "297\n",
      "469.07295871229746\n",
      "298\n",
      "469.32220852753517\n",
      "299\n",
      "468.93622080411023\n",
      "300\n",
      "468.99016205649554\n",
      "301\n",
      "469.7332910123194\n",
      "302\n",
      "470.74104304289665\n",
      "303\n",
      "470.8057337968843\n",
      "304\n",
      "470.63957349500595\n",
      "305\n",
      "470.465980112983\n",
      "306\n",
      "470.36023268860663\n",
      "307\n",
      "470.1644369259344\n",
      "308\n",
      "474.0951344500553\n",
      "309\n",
      "477.1741602848841\n",
      "310\n",
      "478.3109481751231\n",
      "311\n",
      "480.2452812292803\n",
      "312\n",
      "479.49348044397937\n",
      "313\n",
      "483.3018748369481\n",
      "314\n",
      "484.29283057236927\n",
      "315\n",
      "484.68742687838943\n",
      "316\n",
      "484.9546511315858\n",
      "317\n",
      "485.91633804838386\n",
      "318\n",
      "486.9324199797704\n",
      "319\n",
      "488.53984876522065\n",
      "320\n",
      "490.039926844918\n",
      "321\n",
      "490.1374816473235\n",
      "322\n",
      "493.87778738056176\n",
      "323\n",
      "494.86861837343554\n",
      "324\n",
      "493.9977547003031\n",
      "325\n",
      "494.9793215406533\n",
      "326\n",
      "500.0993393680328\n",
      "327\n",
      "500.2500390509874\n",
      "328\n",
      "506.713447150819\n",
      "329\n",
      "507.4479045761574\n",
      "330\n",
      "509.74171542925274\n",
      "331\n",
      "510.5272928233872\n",
      "332\n",
      "510.8586250934745\n",
      "333\n",
      "512.1351211110592\n",
      "334\n",
      "514.1820298655093\n",
      "335\n",
      "514.0824781093423\n",
      "336\n",
      "513.8144113327653\n",
      "337\n",
      "514.4110164107584\n",
      "338\n",
      "514.5167515621016\n",
      "339\n",
      "518.4940663780451\n",
      "340\n",
      "520.655120629375\n",
      "341\n",
      "519.8560543060516\n",
      "342\n",
      "521.2146098793618\n",
      "343\n",
      "521.2106434394649\n",
      "344\n",
      "521.1343972780343\n",
      "345\n",
      "522.4230632572235\n",
      "346\n",
      "522.5652283999663\n",
      "347\n",
      "523.2306675697923\n",
      "348\n",
      "523.3698674054004\n",
      "349\n",
      "524.3947894488567\n",
      "350\n",
      "523.9779671777255\n",
      "351\n",
      "523.3590662876039\n",
      "352\n",
      "522.5946372309627\n",
      "353\n",
      "523.2825657851448\n",
      "354\n",
      "523.7493487220488\n",
      "355\n",
      "524.263375266852\n",
      "356\n",
      "524.3536906752705\n",
      "357\n",
      "525.6232936730197\n",
      "358\n",
      "527.3371636072958\n"
     ]
    }
   ],
   "source": [
    "metadata, series_data = read_tsf('../m4/m4_weekly_dataset.tsf')\n",
    "horizon = 13\n",
    "representation = \"DWT\"\n",
    "level = 7\n",
    "wavelet = \"bior2.2\"\n",
    "transform = \"normal\"\n",
    "window = 12\n",
    "# window = 90\n",
    "\n",
    "# series = pd.read_csv('../m4/m4_monthly_dataset.tsf', sep='\\t', encoding='ISO-8859-1')\n",
    "smapes = []\n",
    "rmses = []\n",
    "for index in range(len(series_data)):\n",
    "    try:\n",
    "        series = series_data.loc[index]['series']\n",
    "\n",
    "        train, test = train_test_stats(pd.Series(series), horizon)\n",
    "        train_tf = transform_train(train, transform)\n",
    "        data = features_target(pd.concat([train_tf, pd.Series([0] * horizon, index=test.index)]), window)\n",
    "        # data = rolling_window(pd.concat([train_tf, pd.Series([0] * horizon, index=test.index)]), window)\n",
    "        X_train, X_test, y_train, _ = train_test_split(data, horizon)\n",
    "        # rg = RidgeCV(alphas=np.logspace(-3, 3, 10))\n",
    "        rg = RandomForestRegressor(random_state=42)\n",
    "        rg.fit(X_train, y_train)\n",
    "\n",
    "        predictions = recursive_rocket2(X_test, rg, train_tf[-window:].tolist(), horizon)\n",
    "\n",
    "        # predictions = recursive_multistep_forecasting(X_test, rg, horizon)\n",
    "        preds = pd.Series(predictions, index=test.index)\n",
    "        preds_real = reverse_regressors(train, preds, format=transform)\n",
    "        mape_result = mape(test, preds_real)\n",
    "\n",
    "        preds_real_array = np.array(preds_real)\n",
    "        preds_real_reshaped = preds_real_array.reshape(1, -1)\n",
    "        test_reshaped = test.values.reshape(1, -1)\n",
    "        smape_result = calculate_smape(preds_real_reshaped, test_reshaped)\n",
    "        rmse_result = calculate_rmse(preds_real_reshaped, test_reshaped)\n",
    "        # pocid_result = pocid(test, preds_real)\n",
    "        print(index)\n",
    "        rmses.append(rmse_result)\n",
    "        smapes.append(smape_result)\n",
    "        print(np.mean(rmses))\n",
    "    except Exception as e:\n",
    "        print(f'Index: {index} | {e}')\n",
    "        print(len(series))\n",
    "        continue\n",
    "    # print(pocid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11680836857304337"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(smapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527.3371636072958"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rmses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
