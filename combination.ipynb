{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U aeon\n",
    "#!pip install aeon[all_extras]\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from aeon.visualisation import plot_series\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from all_functions import *\n",
    "import os\n",
    "from aeon.clustering.averaging import elastic_barycenter_average\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from VotingCombination import VotingCombination\n",
    "from sklearn.svm import SVR\n",
    "import os\n",
    "from tslearn.barycenters import \\\n",
    "    euclidean_barycenter, \\\n",
    "    dtw_barycenter_averaging, \\\n",
    "    dtw_barycenter_averaging_subgradient, \\\n",
    "    softdtw_barycenter\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "def get_predictions_csv(path, format, start_index):\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    results = {}\n",
    "    params = {}\n",
    "    # for format in formats:\n",
    "    filtered_df = df[df['DATA'] == format]\n",
    "    \n",
    "    columns_p1_to_p12 = filtered_df.loc[:, 'P1':'P12']\n",
    "    \n",
    "    # values_list = columns_p1_to_p12.values.tolist()\n",
    "    values_list = columns_p1_to_p12.values.flatten().tolist()     \n",
    "    results = pd.Series(values_list, index=start_index)\n",
    "    params = filtered_df['PARAMS'].iloc[0]\n",
    "            \n",
    "    return results, params\n",
    "\n",
    "def get_params_model(caminho_arquivo, transformation):\n",
    "    df = pd.read_csv(caminho_arquivo, sep=';')\n",
    "    \n",
    "    df_filtrado = df[df['DATA'] == transformation]\n",
    "    params_dict = ast.literal_eval(df_filtrado['PARAMS'].iloc[0])\n",
    "    \n",
    "    return params_dict\n",
    "\n",
    "def convert_to_list(series_str):\n",
    "    return eval(series_str)\n",
    "\n",
    "def get_preds_hybrid(path, test_date, start_index):\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    results = {}\n",
    "    filtered_df = df[df['test_range'] == test_date]\n",
    "    columns_p1_to_p12 = filtered_df.loc[:, 'P1':'P12']\n",
    "    values_list = columns_p1_to_p12.values.flatten().tolist()     \n",
    "    results = pd.Series(values_list, index=start_index)\n",
    "    return results\n",
    "\n",
    "def save_csv(nome, csv_file, uf, derivado, models, series, test, preds, horizon=12, window=12):\n",
    "    y_baseline = series[-horizon*2:-horizon].values\n",
    "    rmse_result = rmse(test, preds)\n",
    "    mape_result = mape(test, preds)\n",
    "    pocid_result = pocid(test, preds)\n",
    "    pbe_result = pbe(test, preds)\n",
    "    mcpm_result = mcpm(rmse_result, mape_result, pocid_result)\n",
    "    mase_result = mase(test, preds, y_baseline)\n",
    "\n",
    "    df_result = pd.DataFrame({'DATA': nome, 'UF': uf, 'PRODUCT': derivado, 'MODEL':  f\"{'_'.join(models)}\", 'PARAMS': str({}), 'WINDOW': window, 'HORIZON': horizon,  \n",
    "                                            'RMSE': rmse_result, 'MAPE': mape_result, 'POCID': pocid_result, 'PBE': pbe_result, 'MASE': mase_result,\n",
    "                                            'P1': preds[0], 'P2': preds[1], 'P3': preds[2], 'P4': preds[3], 'P5': preds[4],\n",
    "                                            'P6': preds[5], 'P7': preds[6], 'P8': preds[7], 'P9': preds[8], 'P10': preds[9],\n",
    "                                            'P11': preds[10], 'P12': preds[11]\n",
    "                                            }, index=[0])\n",
    "    df_result.to_csv(csv_file, sep=';', mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivados = [\"gasolinac\"]\n",
    "transformations = [\"normal\", \"deseasonal\", \"log\"]\n",
    "models = [\"knn\", \"rf\", \"deepar\", \"svr\", \"catboost\", \"arima\"]\n",
    "noResid = False\n",
    "test_date = '2023-03_2024-02'\n",
    "results_file = './combination'\n",
    "horizon = 12\n",
    "window = 12\n",
    "\n",
    "dirs = [\n",
    "    '../datasets/venda/mensal/uf/gasolinac/',\n",
    "    # '../datasets/venda/mensal/uf/etanolhidratado/',\n",
    "    # '../datasets/venda/mensal/uf/glp/',\n",
    "    # '../datasets/venda/mensal/uf/oleodiesel/',\n",
    "    # '../datasets/venda/mensal/uf/querosenedeaviacao/',\n",
    "]\n",
    "colunas = ['DATA', 'UF', 'PRODUCT', 'MODEL', 'PARAMS', 'WINDOW', 'HORIZON', 'RMSE', 'MAPE', 'POCID', 'PBE', 'MASE',\n",
    "           'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12',\n",
    "           ]\n",
    "for directory in dirs:\n",
    "    for file in os.listdir(directory) :\n",
    "        if file.endswith('.csv'):\n",
    "            uf = file.split(\"_\")[1].upper()\n",
    "            derivado = file.split(\"_\")[2].split(\".\")[0]\n",
    "            full_path = os.path.join(directory, file)\n",
    "            series = read_series(full_path)\n",
    "            _, test = train_test_stats(series, horizon)\n",
    "\n",
    "            predictions = {}\n",
    "            preds_elastic = []\n",
    "            preds_barycenter = []\n",
    "            \n",
    "            for model in models:\n",
    "                for transform in transformations:\n",
    "                    series_preds = get_preds_hybrid(f'./results_hybrid/{model}/{derivado}/{transform}/transform_{uf}.csv', test_date, test.index)\n",
    "                    predictions[f'{model}_{transform}'] = series_preds\n",
    "                    preds_elastic.append(np.array([[series_preds.values]]))\n",
    "                    preds_barycenter.append(series_preds.values)\n",
    "\n",
    "                    if noResid:\n",
    "                        series_noresid = get_preds_hybrid(f'./results_hybrid/{model}_noresid/{derivado}/{transform}/transform_{uf}.csv', test_date, test.index)\n",
    "                        predictions[f'{model}_noresid_{transform}'] = series_noresid\n",
    "                        preds_elastic.append(np.array([[series_noresid.values]]))\n",
    "                        preds_barycenter.append(series_noresid.values)\n",
    "\n",
    "\n",
    "            voting = VotingCombination(predictions, combination='median')\n",
    "            preds_median = voting.predict()\n",
    "\n",
    "            path_derivado = results_file + f'/{derivado}'\n",
    "            csv_file = path_derivado + f\"/transform_{uf.upper()}.csv\"\n",
    "            os.makedirs(path_derivado, exist_ok=True)\n",
    "            if not os.path.exists(csv_file):\n",
    "                pd.DataFrame(columns=colunas).to_csv(csv_file, sep=';', index=False)\n",
    "                \n",
    "            save_csv(\"median\",csv_file, uf, derivado, models, series, test, preds_median, horizon, window)\n",
    "\n",
    "            voting = VotingCombination(predictions, combination='mean')\n",
    "            preds_mean = voting.predict()\n",
    "            save_csv(\"mean\",csv_file, uf, derivado, models, series, test, preds_mean, horizon, window)\n",
    "\n",
    "            preds_softdtw = softdtw_barycenter(preds_barycenter, max_iter=35, gamma=0.01)\n",
    "            preds_softdtw = pd.Series(preds_softdtw.flatten().tolist(), index=test.index)\n",
    "            save_csv(\"softdtw_barycenter\",csv_file, uf, derivado, models, series, test, preds_softdtw, horizon, window)\n",
    "\n",
    "            preds_dtw_subgradient = dtw_barycenter_averaging_subgradient(preds_barycenter, max_iter=35)\n",
    "            preds_dtw_subgradient = pd.Series(preds_dtw_subgradient.flatten().tolist(), index=test.index)\n",
    "            save_csv(\"DBA_subgradient\", csv_file, uf, derivado, models, series, test, preds_dtw_subgradient, horizon, window)\n",
    "\n",
    "            preds_dtw_avg = dtw_barycenter_averaging(preds_barycenter, max_iter=35)\n",
    "            preds_dtw_avg = pd.Series(preds_dtw_avg.flatten().tolist(), index=test.index)\n",
    "            save_csv(\"DBA\", csv_file, uf, derivado, models, series, test, preds_dtw_avg, horizon, window)\n",
    "\n",
    "            capt = np.vstack(preds_elastic)\n",
    "            elastic = elastic_barycenter_average(capt, distance=\"twe\", reach=15)\n",
    "            preds_elastic = pd.Series(elastic[0].tolist(), index=test.index)\n",
    "            save_csv(\"EBA_twe\", csv_file, uf, derivado, models, series, test, preds_elastic, horizon, window)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
