{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anp/anaconda3/lib/python3.11/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n",
      "/home/anp/anaconda3/lib/python3.11/site-packages/rapids_dask_dependency/dask_loader.py:36: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 11.0.0. Please consider upgrading.\n",
      "  mod = importlib.import_module(spec.name)\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U aeon\n",
    "#!pip install aeon[all_extras]\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from aeon.visualisation import plot_series\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from all_functions import *\n",
    "import os\n",
    "from aeon.clustering.averaging import elastic_barycenter_average\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from VotingCombination import VotingCombination\n",
    "from sklearn.svm import SVR\n",
    "import os\n",
    "from tslearn.barycenters import \\\n",
    "    euclidean_barycenter, \\\n",
    "    dtw_barycenter_averaging, \\\n",
    "    dtw_barycenter_averaging_subgradient, \\\n",
    "    softdtw_barycenter\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "def get_predictions_csv(path, format, start_index):\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    results = {}\n",
    "    params = {}\n",
    "    # for format in formats:\n",
    "    filtered_df = df[df['DATA'] == format]\n",
    "    \n",
    "    columns_p1_to_p12 = filtered_df.loc[:, 'P1':'P12']\n",
    "    \n",
    "    # values_list = columns_p1_to_p12.values.tolist()\n",
    "    values_list = columns_p1_to_p12.values.flatten().tolist()     \n",
    "    results = pd.Series(values_list, index=start_index)\n",
    "    params = filtered_df['PARAMS'].iloc[0]\n",
    "            \n",
    "    return results, params\n",
    "\n",
    "def get_params_model(caminho_arquivo, transformation):\n",
    "    df = pd.read_csv(caminho_arquivo, sep=';')\n",
    "    \n",
    "    df_filtrado = df[df['DATA'] == transformation]\n",
    "    params_dict = ast.literal_eval(df_filtrado['PARAMS'].iloc[0])\n",
    "    \n",
    "    return params_dict\n",
    "\n",
    "def convert_to_list(series_str):\n",
    "    return eval(series_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleocombustivel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n",
      "oleodiesel\n"
     ]
    }
   ],
   "source": [
    "dirs = [\n",
    "    # '../datasets/venda/mensal/uf/gasolinac/',\n",
    "    # '../datasets/venda/mensal/uf/etanolhidratado/',\n",
    "    # '../datasets/venda/mensal/uf/gasolinadeaviacao/',\n",
    "    # '../datasets/venda/mensal/uf/glp/',\n",
    "    # '../datasets/venda/mensal/uf/oleocombustivel/',\n",
    "    '../datasets/venda/mensal/uf/oleodiesel/',\n",
    "    '../datasets/venda/mensal/uf/querosenedeaviacao/',\n",
    "    # '../datasets/venda/mensal/uf/queroseneiluminante/',\n",
    "]\n",
    "horizon = 12\n",
    "window = 12\n",
    "\n",
    "cols =  ['DATA', 'transformation', 'UF', 'PRODUCT', 'MODEL', 'PARAMS', 'WINDOW', 'HORIZON', 'RMSE', 'MAPE', 'POCID', 'PBE', 'MASE',\n",
    "           'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12','MCPM', \n",
    "           ]\n",
    "results_file = f'./combination/arima_svr_error'\n",
    "transformations = ['normal', 'log', 'deseasonal']\n",
    "for directory in dirs:\n",
    "  path_derivado = f'{results_file}/{derivado}'\n",
    "  os.makedirs(path_derivado, exist_ok=True)\n",
    "  for file in os.listdir(directory):\n",
    "    for transform in transformations:\n",
    "      estado = file.split(\"_\")[1].upper()\n",
    "      derivado = file.split(\"_\")[2].split(\".\")[0]\n",
    "      series = read_series(f'../datasets/venda/mensal/uf/{derivado}/mensal_{estado.lower()}_{derivado}.csv')\n",
    "      _, test = train_test_stats(series, horizon)\n",
    "\n",
    "      dado = pd.read_csv(f'./results_hybrid/arima/{derivado}/{transform}/transform_{estado}.csv', sep=\";\")\n",
    "      filter_arima = dado[dado['test_range'] == '2023-03_2024-02']\n",
    "      columns_p1_to_p12 = filter_arima.loc[:, 'P1':'P12']\n",
    "      arima_preds = columns_p1_to_p12.values.flatten().tolist()        \n",
    "      dado['error_series'] = dado['error_series'].apply(convert_to_list)\n",
    "      reversed_lists = dado['error_series'].iloc[::-1]\n",
    "\n",
    "      period_index = pd.period_range(start='1993-03', end='2024-02', freq='M')\n",
    "      error = []\n",
    "      for lst in reversed_lists:\n",
    "          error.extend(lst)\n",
    "      error_series = pd.Series(error, index=period_index)\n",
    "      train_error, test_error = train_test_stats(error_series, horizon)\n",
    "      \n",
    "      transformer = STLTransformer(sp=12)  \n",
    "      result = transformer.fit(train_error)\n",
    "      train_error_st = result.trend_ + result.seasonal_\n",
    "\n",
    "      csv_path = f'{path_derivado}/transform_{estado}.csv'\n",
    "      if not os.path.exists(csv_path):\n",
    "        pd.DataFrame(columns=cols).to_csv(csv_path, sep=';', index=False)\n",
    "\n",
    "      # previsao do erro direto\n",
    "      data = rolling_window(error_series, window)\n",
    "      data = data.dropna()\n",
    "      X_train, X_test, y_train, _ = train_test_split(data, horizon)\n",
    "\n",
    "      svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "      svr_rbf.fit(X_train, y_train)\n",
    "\n",
    "      predictions = recursive_multistep_forecasting(X_test, svr_rbf, horizon)\n",
    "      mean_norm, std_norm = get_stats_norm(error_series, horizon, window)\n",
    "\n",
    "      predictions_rescaled = znorm_reverse(pd.Series(predictions, index=test_error.index), mean_norm, std_norm)\n",
    "      preds = pd.Series(predictions_rescaled, index=test_error.index)\n",
    "      combined = pd.Series(arima_preds + preds.values, index=test.index)\n",
    "\n",
    "      y_baseline = series[-horizon*2:-horizon].values\n",
    "      rmse_result = rmse(test, combined)\n",
    "      mape_result = mape(test, combined)\n",
    "      pocid_result = pocid(test, combined)\n",
    "      pbe_result = pbe(test, combined)\n",
    "      mase_result =  mase(test, combined, y_baseline)\n",
    "      mcpm_result = mcpm(rmse_result, mape_result, pocid_result)\n",
    "\n",
    "      df_temp = pd.DataFrame({'DATA': 'error', 'transformation':  transform, 'UF': estado, 'PRODUCT': derivado, 'MODEL': 'ARIMA+SVR', 'PARAMS': 'sum', 'WINDOW': window, 'HORIZON': horizon,  \n",
    "                                              'RMSE': rmse_result, 'MAPE': mape_result, 'POCID': pocid_result, 'PBE': pbe_result, 'MASE': mase_result, 'MCPM': mcpm_result,\n",
    "                                              'P1': combined[0], 'P2': combined[1], 'P3': combined[2], 'P4': combined[3], 'P5': combined[4],\n",
    "                                              'P6': combined[5], 'P7': combined[6], 'P8': combined[7], 'P9': combined[8], 'P10': combined[9],\n",
    "                                              'P11': combined[10], 'P12': combined[11]\n",
    "                                              }, index=[0])\n",
    "      df_temp.to_csv(csv_path, sep=';', mode='a', header=False, index=False)\n",
    "\n",
    "\n",
    "    #previsao do erro sem componente de residual\n",
    "    series_error_st = pd.concat([train_error_st, pd.Series([0,0,0,0,0,0,0,0,0,0,0,0], index=test.index)])\n",
    "    data = rolling_window(series_error_st, window)\n",
    "\n",
    "    data = data.dropna()\n",
    "    X_train, X_test, y_train, _ = train_test_split(data, horizon)\n",
    "\n",
    "    svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "    svr_rbf.fit(X_train, y_train)\n",
    "\n",
    "    predictions = recursive_multistep_forecasting(X_test, svr_rbf, horizon)\n",
    "    mean_norm, std_norm = get_stats_norm(series_error_st, horizon, window)\n",
    "\n",
    "    # Reescala as predições\n",
    "    predictions_rescaled = znorm_reverse(pd.Series(predictions, index=test_error.index), mean_norm, std_norm)\n",
    "\n",
    "\n",
    "    preds_noresid = pd.Series(predictions_rescaled, index=test_error.index)\n",
    "\n",
    "    combined_error_noresid = pd.Series(arima_preds + preds_noresid.values, index=test.index)\n",
    "\n",
    "    y_baseline = series[-horizon*2:-horizon].values\n",
    "    rmse_result = rmse(test, combined_error_noresid)\n",
    "    mape_result = mape(test, combined_error_noresid)\n",
    "    pocid_result = pocid(test, combined_error_noresid)\n",
    "    pbe_result = pbe(test, combined_error_noresid)\n",
    "    mase_result =  mase(test, combined_error_noresid, y_baseline)\n",
    "    mcpm_result = mcpm(rmse_result, mape_result, pocid_result)\n",
    "\n",
    "    df_temp = pd.DataFrame({'DATA': 'error_noresid', 'transformation':  transform, 'UF': estado, 'PRODUCT': derivado, 'MODEL': 'ARIMA+SVR', 'PARAMS': 'sum', 'WINDOW': window, 'HORIZON': horizon,  \n",
    "                                            'RMSE': rmse_result, 'MAPE': mape_result, 'POCID': pocid_result, 'PBE': pbe_result, 'MASE': mase_result, 'MCPM': mcpm_result,\n",
    "                                            'P1': combined_error_noresid[0], 'P2': combined_error_noresid[1], 'P3': combined_error_noresid[2], 'P4': combined_error_noresid[3], 'P5': combined_error_noresid[4],\n",
    "                                            'P6': combined_error_noresid[5], 'P7': combined_error_noresid[6], 'P8': combined_error_noresid[7], 'P9': combined_error_noresid[8], 'P10': combined_error_noresid[9],\n",
    "                                            'P11': combined_error_noresid[10], 'P12': combined_error_noresid[11]\n",
    "                                            }, index=[0])\n",
    "    df_temp.to_csv(csv_path, sep=';', mode='a', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
