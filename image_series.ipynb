{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from all_functions import *\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from aeon.visualisation import plot_series\n",
    "import pywt\n",
    "from scipy import signal\n",
    "from pyts.image import MarkovTransitionField\n",
    "from pyts.image import GramianAngularField\n",
    "from pyts.image import RecurrencePlot\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, RidgeCV, HuberRegressor, Lasso, LassoLarsCV\n",
    "from aeon.transformations.collection.convolution_based import (\n",
    "    MiniRocket,\n",
    "    Rocket,\n",
    "    MiniRocketMultivariateVariable,\n",
    ")\n",
    "import warnings\n",
    "\n",
    "def rolling_window_image_concat(series, window, rep1, rep2, wavelet1, wavelet2, level1, level2):\n",
    "  data = []\n",
    "  for i in range(len(series)-window):\n",
    "    example = np.array(series[i:i+window+1])\n",
    "    target = example[-1]\n",
    "\n",
    "    features = np.delete(example, -1)\n",
    "    features_norm = znorm(features)\n",
    "    \n",
    "    target_norm = znorm_by(target, features)\n",
    "\n",
    "    rep_features1 = transform_series(features_norm, rep1, wavelet1, level1)\n",
    "    rep_features2 = transform_series(features_norm, rep2, wavelet2, level2)\n",
    "\n",
    "    reps = np.concatenate((rep_features1.flatten(),rep_features2.flatten()))\n",
    "    feat_target = np.concatenate((reps, [target_norm]))\n",
    "    data.append(feat_target)\n",
    "  df = pd.DataFrame(data)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class DilatedConvModel(nn.Module):\n",
    "    def __init__(self, input_channels=1, num_filters=128, window_size=20):\n",
    "        super(DilatedConvModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, num_filters, kernel_size=1, stride=1, padding=1)  # kernel_size 1\n",
    "        self.conv2 = nn.Conv1d(num_filters, num_filters, kernel_size=2, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(num_filters, num_filters, kernel_size=2,  stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Ajuste o número de saídas na camada totalmente conectada\n",
    "        self.fc = nn.Linear(num_filters * (window_size // 4), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Input shape:\", x.shape)\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        print(\"Shape after conv1 and pooling:\", x.shape)\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        print(\"Shape after conv2 and pooling:\", x.shape)\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        print(\"Shape after conv3 and pooling:\", x.shape)\n",
    "        x = x.view(x.size(0), -1)  # Achatar para a camada totalmente conectada\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Função para transformar a série em tensores\n",
    "def create_dataset(series, window_size=10):\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - window_size):\n",
    "        X.append(series[i:i + window_size])  # Janela de entrada\n",
    "        y.append(series[i + window_size])           # Valor a ser previsto\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ler os dados do arquivo TSF\n",
    "metadata, series_data = read_tsf('../m4/m4_hourly_dataset.tsf')\n",
    "for meta in metadata:\n",
    "    if '@horizon' in meta:\n",
    "        horizon = int(meta[9:])\n",
    "\n",
    "series = series_data.loc[0]['series']\n",
    "train_series, test_series = train_test_stats(pd.Series(series), horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([687, 1, 13])\n",
      "Shape after conv1 and pooling: torch.Size([687, 128, 7])\n",
      "Shape after conv2 and pooling: torch.Size([687, 128, 4])\n",
      "Shape after conv3 and pooling: torch.Size([687, 128, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (687x256 and 640x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 31\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(X_train_tensor)  \u001b[38;5;66;03m# Passar dados pelo modelo\u001b[39;00m\n\u001b[1;32m     32\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_train_tensor)  \u001b[38;5;66;03m# Calcular perda\u001b[39;00m\n\u001b[1;32m     33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Retropropagação\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[110], line 25\u001b[0m, in \u001b[0;36mDilatedConvModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape after conv3 and pooling:\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Achatar para a camada totalmente conectada\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (687x256 and 640x1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Aumentando o tamanho da janela\n",
    "window_size = 10  # Ajuste conforme necessário\n",
    "\n",
    "# Criar dataset\n",
    "X_train, y_train = create_dataset(train_series.tolist(), window_size)\n",
    "X_test, y_test = create_dataset(test_series.tolist(), window_size)\n",
    "\n",
    "# Converter para tensores do PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # Adicionando canal\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)  # Adicionando canal\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Inicializar o modelo, critério e otimizador\n",
    "model = DilatedConvModel(input_channels=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Treinamento do modelo\n",
    "num_epochs = 500  # Ajuste conforme necessário\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)  # Passar dados pelo modelo\n",
    "    loss = criterion(outputs, y_train_tensor)  # Calcular perda\n",
    "    loss.backward()  # Retropropagação\n",
    "    optimizer.step()  # Atualizar pesos\n",
    "    if (epoch + 1) % 10 == 0:  # Exibir a cada 10 épocas\n",
    "        print(f'Época {epoch+1}, Perda: {loss.item():.4f}')\n",
    "\n",
    "# Avaliação do modelo\n",
    "model.eval()  # Modo de avaliação\n",
    "with torch.no_grad():  # Não calcular gradientes\n",
    "    y_test_pred = model(X_test_tensor)\n",
    "\n",
    "# Converter as previsões de volta para NumPy para comparação\n",
    "\n",
    "def recursive_forecast(model, input_seq, horizon):\n",
    "    model.eval()  # Modo de avaliação\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():  # Não calcular gradientes\n",
    "        for _ in range(horizon):\n",
    "            # Fazer previsão\n",
    "            input_tensor = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0).unsqueeze(1)  # Shape: [1, 1, window_size]\n",
    "            pred = model(input_tensor)\n",
    "            predictions.append(pred.item())  # Armazenar a previsão\n",
    "            \n",
    "            # Atualizar a sequência de entrada\n",
    "            input_seq = np.append(input_seq[1:], pred.numpy())  # Deslocar a janela e adicionar a previsão\n",
    "            \n",
    "    return np.array(predictions)\n",
    "\n",
    "last_input_seq = test_series[-window_size:].tolist()  # Últimos valores da série para iniciar a previsão\n",
    "predictions = recursive_forecast(model, last_input_seq, horizon)\n",
    "\n",
    "print(predictions)  # Exibir previsões\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotando os valores reais\n",
    "plt.plot(test_series.tolist(), label='Real', color='blue')\n",
    "\n",
    "# Plotando as previsões\n",
    "plt.plot(predictions, label='Valores Previsto', color='red')\n",
    "\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Valores')\n",
    "plt.title('Previsão da Série Temporal com Convoluções Dilatadas')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700    619.0\n",
       "701    565.0\n",
       "702    532.0\n",
       "703    495.0\n",
       "704    481.0\n",
       "705    467.0\n",
       "706    473.0\n",
       "707    488.0\n",
       "708    501.0\n",
       "709    534.0\n",
       "710    576.0\n",
       "711    639.0\n",
       "712    712.0\n",
       "713    772.0\n",
       "714    830.0\n",
       "715    880.0\n",
       "716    893.0\n",
       "717    896.0\n",
       "718    891.0\n",
       "719    854.0\n",
       "720    803.0\n",
       "721    769.0\n",
       "722    751.0\n",
       "723    701.0\n",
       "724    635.0\n",
       "725    572.0\n",
       "726    532.0\n",
       "727    493.0\n",
       "728    477.0\n",
       "729    468.0\n",
       "730    464.0\n",
       "731    477.0\n",
       "732    492.0\n",
       "733    519.0\n",
       "734    568.0\n",
       "735    624.0\n",
       "736    696.0\n",
       "737    761.0\n",
       "738    812.0\n",
       "739    836.0\n",
       "740    838.0\n",
       "741    829.0\n",
       "742    807.0\n",
       "743    785.0\n",
       "744    756.0\n",
       "745    719.0\n",
       "746    703.0\n",
       "747    659.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
