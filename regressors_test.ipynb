{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/lucas/lib/python3.11/site-packages/rapids_dask_dependency/dask_loader.py:36: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 11.0.0. Please consider upgrading.\n",
      "  mod = importlib.import_module(spec.name)\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U aeon\n",
    "#!pip install aeon[all_extras]\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from aeon.visualisation import plot_series\n",
    "from all_functions import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from aeon.transformations.detrend import STLTransformer\n",
    "import ast\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import os\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from datetime import datetime\n",
    "from distutils.util import strtobool\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "def convert_to_list(series_str):\n",
    "    return eval(series_str)\n",
    "\n",
    "def get_preds_hybrid(path, test_date, start_index):\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    results = {}\n",
    "    filtered_df = df[df['test_range'] == test_date]\n",
    "    columns_p1_to_p12 = filtered_df.loc[:, 'P1':'P12']\n",
    "    values_list = columns_p1_to_p12.values.flatten().tolist()     \n",
    "    results = pd.Series(values_list, index=start_index)\n",
    "    return results\n",
    "\n",
    "def generate_index(start_date, end_date):\n",
    "    end_date_dt = pd.to_datetime(end_date)\n",
    "    \n",
    "    start_date_dt = pd.to_datetime(start_date)\n",
    "    \n",
    "    index = pd.period_range(start=start_date_dt, end=end_date_dt, freq='M')\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arima\n"
     ]
    }
   ],
   "source": [
    "modelos = [\n",
    "    \"ETS\",\n",
    "    \"arima\", \n",
    "    # \"catboost\", \"ridge\",\n",
    "    # \"SWT_ridge\", \"CWT_ridge\", \"DWT_ridge\", \"FIRTS_ridge\", \"STFT_ridge\", \"RP_ridge\", \"MTF_ridge\", \"WPT_ridge\", \"GASF_ridge\", \"GADF_ridge\"\n",
    "    ]\n",
    "derivados = [\n",
    "            \"gasolinac\", \"etanolhidratado\", \"oleodiesel\", \"glp\", \n",
    "            #  \"querosenedeaviacao\"\n",
    "            ]\n",
    "transformations = [\"normal\", \"deseasonal\"]\n",
    "dates = [\"2019-03_2020-02\",\"2020-03_2021-02\",\"2021-03_2022-02\",\"2022-03_2023-02\",\"2023-03_2024-02\"]\n",
    "\n",
    "\n",
    "for modelo in modelos:\n",
    "    print(modelo)\n",
    "    for derivado in derivados:\n",
    "        for transformation in transformations:\n",
    "            path_folders = f'./paper_roma/{modelo}/{derivado}/{transformation}/'\n",
    "            all_mape = []\n",
    "            all_pocid = []\n",
    "            all_pbe = []\n",
    "            all_rmse = []\n",
    "            if os.path.exists(path_folders):\n",
    "                for filename in os.listdir(path_folders):\n",
    "                    all_preds = []\n",
    "                    all_test = []\n",
    "                    if filename.endswith('.csv'):\n",
    "                        for date in dates:\n",
    "                            file_path = os.path.join(path_folders, filename)\n",
    "\n",
    "                            uf = filename.split(\"_\")[1].split(\".\")[0]\n",
    "\n",
    "                            start_date, end_date = date.split('_')\n",
    "                            test_index = generate_index(start_date, end_date)\n",
    "                            # test_real = get_test_real(series, start_date, end_date)\n",
    "                            preds = get_preds_hybrid(file_path, date, test_index)\n",
    "\n",
    "                            series = read_series(f'../datasets/venda/mensal/uf/{derivado}/mensal_{uf.lower()}_{derivado}.csv')\n",
    "                            test_real = get_test_real(series, start_date, end_date)\n",
    "\n",
    "                            all_preds.extend(preds.tolist())\n",
    "                            all_test.extend(test_real)\n",
    "\n",
    "                        # y_baseline = train[-horizon*1:].values\n",
    "                        rmse_result = rmse(all_test, all_preds)\n",
    "                        mape_result = mape(all_test, all_preds)\n",
    "                        pocid_result = pocid(all_test, all_preds)\n",
    "                        pbe_result = pbe(pd.Series(all_test), pd.Series(all_preds))\n",
    "                        # mase_result = mase(test, preds_real, y_baseline)\n",
    "\n",
    "                        all_pocid.append(pocid_result)\n",
    "                        all_pbe.append(pbe_result)\n",
    "                        all_rmse.append(rmse_result)\n",
    "                        all_mape.append(mape_result)\n",
    "\n",
    "            #realizar media de all_rmse, all_mape, all_pocid, all_pbe\n",
    "            #salve em um arquivo csv com a forma de append para adicionar novas linhas\n",
    "            #colunas\n",
    "            #representacao, RMSE, MAPE, POCID, PBE\n",
    "\n",
    "            #onde representacao Ã© {model}_{transformation}\n",
    "            if len(all_rmse) > 0:\n",
    "                media_rmse = sum(all_rmse) / len(all_rmse)\n",
    "                media_mape = sum(all_mape) / len(all_mape)\n",
    "                media_pocid = sum(all_pocid) / len(all_pocid)\n",
    "                media_pbe = sum(all_pbe) / len(all_pbe)\n",
    "\n",
    "                representacao = f\"{modelo}_{transformation}\"\n",
    "\n",
    "                data = {\n",
    "                    \"representacao\": [representacao],\n",
    "                    \"RMSE\": [media_rmse],\n",
    "                    \"MAPE\": [media_mape],\n",
    "                    \"POCID\": [media_pocid],\n",
    "                    \"PBE\": [media_pbe],\n",
    "                    \"derivado\": [derivado]\n",
    "                }\n",
    "\n",
    "                df = pd.DataFrame(data)\n",
    "\n",
    "                os.makedirs('./metrics/', exist_ok=True)\n",
    "                csv_file = f'./metrics/{derivado}.csv'\n",
    "\n",
    "                df.to_csv(csv_file, mode='a', header=not pd.io.common.file_exists(csv_file), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
