{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from all_functions import *\n",
    "from streamfuels.datasets import DatasetLoader\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NHITS, NBEATS, MLP\n",
    "from metaforecast.ensembles import ADE\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# python -m jupyter nbconvert --to notebook --execute create_rf_dataframe_fixed.ipynb --stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal\n",
    "df_rf = pd.read_csv('./timeseries/mestrado/resultados/rf/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_rf = df_rf[df_rf['final_test'] != '2024-11-30']\n",
    "\n",
    "df_catboost = pd.read_csv('./timeseries/mestrado/resultados/catboost/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_catboost = df_catboost[df_catboost['final_test'] != '2024-11-30']\n",
    "\n",
    "df_svr = pd.read_csv('./timeseries/mestrado/resultados/svr/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_svr = df_svr[df_svr['final_test'] != '2024-11-30']\n",
    "\n",
    "#estatisticos\n",
    "df_ets = pd.read_csv('./timeseries/mestrado/resultados/ETS/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_ets = df_ets[df_ets['final_test'] != '2024-11-30']\n",
    "\n",
    "df_arima = pd.read_csv('./timeseries/mestrado/resultados/ARIMA/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_arima = df_arima[df_arima['final_test'] != '2024-11-30']\n",
    "\n",
    "df_theta = pd.read_csv('./timeseries/mestrado/resultados/THETA/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_theta = df_theta[df_theta['final_test'] != '2024-11-30']\n",
    "\n",
    "#FOURIER\n",
    "df_ft_rf = pd.read_csv('./timeseries/mestrado/resultados/ONLY_FT_rf/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_ft_rf = df_ft_rf[df_ft_rf['final_test'] != '2024-11-30']\n",
    "\n",
    "df_ft_catboost = pd.read_csv('./timeseries/mestrado/resultados/ONLY_FT_catboost/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_ft_catboost = df_ft_catboost[df_ft_catboost['final_test'] != '2024-11-30']\n",
    "\n",
    "df_ft_svr = pd.read_csv('./timeseries/mestrado/resultados/ONLY_FT_svr/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_ft_svr = df_ft_svr[df_ft_svr['final_test'] != '2024-11-30']\n",
    "\n",
    "#CWT\n",
    "df_cwt_rf = pd.read_csv('./timeseries/mestrado/resultados/ONLY_CWT_rf/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_cwt_rf = df_cwt_rf[df_cwt_rf['final_test'] != '2024-11-30']\n",
    "\n",
    "df_cwt_catboost = pd.read_csv('./timeseries/mestrado/resultados/ONLY_CWT_catboost/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_cwt_catboost = df_cwt_catboost[df_cwt_catboost['final_test'] != '2024-11-30']\n",
    "\n",
    "df_cwt_svr = pd.read_csv('./timeseries/mestrado/resultados/ONLY_CWT_svr/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_cwt_svr = df_cwt_svr[df_cwt_svr['final_test'] != '2024-11-30']\n",
    "\n",
    "#DWT\n",
    "df_dwt_rf = pd.read_csv('./timeseries/mestrado/resultados/ONLY_DWT_rf/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_dwt_rf = df_dwt_rf[df_dwt_rf['final_test'] != '2024-11-30']\n",
    "\n",
    "df_dwt_catboost = pd.read_csv('./timeseries/mestrado/resultados/ONLY_DWT_catboost/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_dwt_catboost = df_dwt_catboost[df_dwt_catboost['final_test'] != '2024-11-30']\n",
    "\n",
    "df_dwt_svr = pd.read_csv('./timeseries/mestrado/resultados/ONLY_DWT_svr/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_dwt_svr = df_dwt_svr[df_dwt_svr['final_test'] != '2024-11-30']\n",
    "\n",
    "\n",
    "#FT + Original\n",
    "df_ft_rf_original = pd.read_csv('./timeseries/mestrado/resultados/FT_rf/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_ft_rf_original = df_ft_rf_original[df_ft_rf_original['final_test'] != '2024-11-30']\n",
    "\n",
    "df_ft_catboost_original = pd.read_csv('./timeseries/mestrado/resultados/FT_catboost/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_ft_catboost_original = df_ft_catboost_original[df_ft_catboost_original['final_test'] != '2024-11-30']\n",
    "\n",
    "df_ft_svr_original = pd.read_csv('./timeseries/mestrado/resultados/FT_svr/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_ft_svr_original = df_ft_svr_original[df_ft_svr_original['final_test'] != '2024-11-30']\n",
    "\n",
    "#CWT + Original\n",
    "df_cwt_rf_original = pd.read_csv('./timeseries/mestrado/resultados/CWT_rf/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_cwt_rf_original = df_cwt_rf_original[df_cwt_rf_original['final_test'] != '2024-11-30']\n",
    "\n",
    "df_cwt_catboost_original = pd.read_csv('./timeseries/mestrado/resultados/CWT_catboost/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_cwt_catboost_original = df_cwt_catboost_original[df_cwt_catboost_original['final_test'] != '2024-11-30']\n",
    "\n",
    "df_cwt_svr_original = pd.read_csv('./timeseries/mestrado/resultados/CWT_svr/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_cwt_svr_original = df_cwt_svr_original[df_cwt_svr_original['final_test'] != '2024-11-30']\n",
    "\n",
    "#DWT + Original\n",
    "df_dwt_rf_original = pd.read_csv('./timeseries/mestrado/resultados/DWT_rf/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_dwt_rf_original = df_dwt_rf_original[df_dwt_rf_original['final_test'] != '2024-11-30']\n",
    "\n",
    "df_dwt_catboost_original = pd.read_csv('./timeseries/mestrado/resultados/DWT_catboost/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_dwt_catboost_original = df_dwt_catboost_original[df_dwt_catboost_original['final_test'] != '2024-11-30']\n",
    "\n",
    "df_dwt_svr_original = pd.read_csv('./timeseries/mestrado/resultados/DWT_svr/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_dwt_svr_original = df_dwt_svr_original[df_dwt_svr_original['final_test'] != '2024-11-30']    \n",
    "\n",
    "#naive\n",
    "df_naive_seasonal = pd.read_csv('./timeseries/mestrado/resultados/NaiveSeasonal/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_naive_seasonal = df_naive_seasonal[df_naive_seasonal['final_test'] != '2024-11-30']\n",
    "\n",
    "df_naive_ma = pd.read_csv('./timeseries/mestrado/resultados/NaiveMovingAverage/normal/ANP_MONTHLY.csv', sep=\";\")\n",
    "# df_naive_ma = df_naive_ma[df_naive_ma['final_test'] != '2024-11-30']\n",
    "\n",
    "all_dfs = {\n",
    "   # 'RF':df_rf, 'Catboost':df_catboost, 'SVR':df_svr, \n",
    "         #   'ETS':df_ets, 'ARIMA':df_arima, 'THETA':df_theta, \n",
    "           'FT_RF':df_ft_rf, \n",
    "           'FT_CATBOOST':df_ft_catboost, \n",
    "         #   'FT_SVR':df_ft_svr,\n",
    "        #    'CWT_RF':df_cwt_rf, 'CWT_CATBOOST':df_cwt_catboost, 'CWT_SVR':df_cwt_svr, \n",
    "        #    'DWT_RF':df_dwt_rf, 'DWT_CATBOOST':df_dwt_catboost, 'DWT_SVR':df_dwt_svr,\n",
    "        #    'FT_RF_ORIGINAL':df_ft_rf_original, 'FT_CATBOOST_ORIGINAL':df_ft_catboost_original, 'FT_SVR_ORIGINAL':df_ft_svr_original,\n",
    "        #    'CWT_RF_ORIGINAL':df_cwt_rf_original, 'CWT_CATBOOST_ORIGINAL':df_cwt_catboost_original, 'CWT_SVR_ORIGINAL':df_cwt_svr_original,\n",
    "        #    'DWT_RF_ORIGINAL':df_dwt_rf_original, 'DWT_CATBOOST_ORIGINAL':df_dwt_catboost_original, 'DWT_SVR_ORIGINAL':df_dwt_svr_original,\n",
    "         #   'NAIVE_SEASONAL':df_naive_seasonal, 'NAIVE_MA':df_naive_ma\n",
    "           }\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def calc_errors(y_panel_df, y_insample_df, seasonality, benchmark_model='ETS'):\n",
    "    \"\"\"Calculates OWA of each time series\n",
    "    usign benchmark_model as benchmark.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_panel_df: pandas df\n",
    "        Pandas DataFrame with columns ['unique_id', 'ds', 'y']\n",
    "    y_insample_df: pandas df\n",
    "        Pandas DataFrame with columns ['unique_id', 'ds', 'y']\n",
    "        Train set.\n",
    "    seasonality: int\n",
    "        Frequency of the time seires.\n",
    "    benchmark_model: str\n",
    "        Column name of the benchmark model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "        OWA errors for each time series and each model.\n",
    "    \"\"\"\n",
    "\n",
    "    assert benchmark_model in y_panel_df.columns\n",
    "\n",
    "    y_panel = y_panel_df[['unique_id', 'ds', 'y']]\n",
    "    y_hat_panel_fun = lambda model_name: y_panel_df[['unique_id', 'ds', model_name]].rename(columns={model_name: 'y_hat'})\n",
    "\n",
    "    model_names = set(y_panel_df.columns) - set(y_panel.columns)\n",
    "\n",
    "    errors_smape = y_panel[['unique_id']].drop_duplicates().reset_index(drop=True)\n",
    "    errors_mase = errors_smape.copy()\n",
    "\n",
    "    for model_name in model_names:\n",
    "        errors_smape[model_name] = None\n",
    "        errors_mase[model_name] = None\n",
    "        y_hat_panel = y_hat_panel_fun(model_name)\n",
    "\n",
    "        errors_smape[model_name] = evaluate_panel(y_panel, y_hat_panel, smape)\n",
    "        errors_mase[model_name] = evaluate_panel(y_panel, y_hat_panel, mase, y_insample_df, seasonality)\n",
    "\n",
    "    mean_smape_benchmark = errors_smape[benchmark_model].mean()\n",
    "    mean_mase_benchmark = errors_mase[benchmark_model].mean()\n",
    "\n",
    "    errors_smape = errors_smape.drop(columns=benchmark_model).set_index('unique_id')\n",
    "    errors_mase = errors_mase.drop(columns=benchmark_model).set_index('unique_id')\n",
    "\n",
    "    errors = errors_smape/mean_mase_benchmark + errors_mase/mean_smape_benchmark\n",
    "    errors = 0.5*errors\n",
    "    errors = errors\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "def extract_values(list_str):\n",
    "    if isinstance(list_str, str):\n",
    "        # Remove brackets and split by commas\n",
    "        # This regex matches all numbers (including those with decimal points)\n",
    "        numbers = re.findall(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?', list_str)\n",
    "        return [float(num) for num in numbers]\n",
    "    return []\n",
    "\n",
    "def date_to_number(date_str):\n",
    "    # Convertendo a string para datetime\n",
    "    date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    # Calculando a diferença em anos desde 1993-12-31\n",
    "    base_date = datetime(1993, 12, 31)\n",
    "    years_diff = (date.year - base_date.year)\n",
    "    # Calculando o número baseado no ano\n",
    "    return years_diff \n",
    "\n",
    "\n",
    "# Create an empty DataFrame to store the combined results\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "df_predictions = pd.DataFrame()\n",
    "all_dates = set()\n",
    "for _, row in all_dfs['FT_CATBOOST'].iterrows():\n",
    "    all_dates.add(row['start_test'])\n",
    "\n",
    "# Ordenar as datas em ordem crescente e criar o mapeamento\n",
    "date_to_num = {}\n",
    "dates_sorted = sorted(all_dates)  # Ordena de forma crescente\n",
    "for i, date in enumerate(dates_sorted, 0):  # Começa do 1\n",
    "    date_to_num[date] = i\n",
    "\n",
    "for name, df_model in all_dfs.items():\n",
    "    # For each model, create a DataFrame with unique_id, ds, and predictions\n",
    "    model_data = []\n",
    "    model_data_test = []\n",
    "    \n",
    "    for index, row in df_model.iterrows():\n",
    "        \n",
    "        if row['final_test'] == '2024-11-30':\n",
    "            #dataframe de test\n",
    "            # row_test = row[row['final_test'] == '2024-11-30']\n",
    "            start_ds_test = pd.Timestamp(row['start_test'])\n",
    "            end_ds_test = pd.Timestamp(row['final_test'])\n",
    "            date_range_test = pd.date_range(start=start_ds_test, end=end_ds_test, freq='M')\n",
    "            pred_values_test = extract_values(row['predictions'])\n",
    "            unique_id_test = row['dataset_index']\n",
    "            \n",
    "            start_date_str = row['start_test']\n",
    "          \n",
    "            for i in range(len(date_range_test)):\n",
    "                entry = {\n",
    "                    'unique_id': f\"{unique_id_test}\",\n",
    "                    # 'serie_id': f\"S{unique_id_test}\",\n",
    "                    # 'unique_id': f\"T{date_to_num[start_date_str]}\", \n",
    "                    'ds': date_range_test[i]\n",
    "                }\n",
    "                    \n",
    "                if i < len(pred_values_test):\n",
    "                    entry[name] = pred_values_test[i]\n",
    "                    \n",
    "                model_data_test.append(entry)\n",
    "            \n",
    "        else:    \n",
    "            #dataframe de treino\n",
    "            # row = row[row['final_test'] != '2024-11-30']\n",
    "            start_ds = pd.Timestamp(row['start_test'])\n",
    "            end_ds = pd.Timestamp(row['final_test'])\n",
    "            date_range = pd.date_range(start=start_ds, end=end_ds, freq='M')\n",
    "            y_values = extract_values(row['test'])\n",
    "            pred_values = extract_values(row['predictions'])\n",
    "            unique_id = row['dataset_index']\n",
    "            start_date_str = row['start_test']\n",
    "\n",
    "            for i in range(len(date_range)):\n",
    "                # Only add values that exist in the arrays\n",
    "                entry = {\n",
    "                    # 'serie_id': f\"S{unique_id}\",\n",
    "                    'unique_id': f\"{unique_id}\",\n",
    "                    # 'unique_id': f\"T{date_to_num[start_date_str]}\", \n",
    "                    'ds': date_range[i]\n",
    "                }\n",
    "                \n",
    "                # Add y value if available\n",
    "                if i < len(y_values):\n",
    "                    entry['y'] = y_values[i]\n",
    "                    \n",
    "                # Add prediction value if available\n",
    "                if i < len(pred_values):\n",
    "                    entry[name] = pred_values[i]\n",
    "                    \n",
    "                model_data.append(entry)\n",
    "            \n",
    "\n",
    "    model_df_test = pd.DataFrame(model_data_test)\n",
    "            \n",
    "    if df_predictions.empty:\n",
    "        df_predictions = model_df_test\n",
    "    else:\n",
    "        merge_columns = ['unique_id', 'ds']\n",
    "        if name in model_df_test.columns:\n",
    "            merge_columns.append(name)\n",
    "            \n",
    "        df_predictions = pd.merge(\n",
    "            df_predictions, \n",
    "            model_df_test[merge_columns], \n",
    "            on=['unique_id', 'ds'], \n",
    "            how='outer'\n",
    "        )\n",
    "        \n",
    "        \n",
    "    # Convert to DataFrame\n",
    "    model_df = pd.DataFrame(model_data)\n",
    "            \n",
    "    if combined_df.empty:\n",
    "        # For the first model, initialize the combined DataFrame\n",
    "        combined_df = model_df\n",
    "    else:\n",
    "        # For subsequent models, merge with the existing DataFrame\n",
    "        # Use outer join to keep all rows from both DataFrames\n",
    "        merge_columns = ['unique_id', 'ds']\n",
    "        if name in model_df.columns:\n",
    "            merge_columns.append(name)\n",
    "            \n",
    "        combined_df = pd.merge(\n",
    "            combined_df, \n",
    "            model_df[merge_columns], \n",
    "            on=['unique_id', 'ds'], \n",
    "            how='outer'\n",
    "        )\n",
    "# Sort the final DataFrame\n",
    "combined_df = combined_df.sort_values(by=['unique_id', 'ds'])\n",
    "df_predictions = df_predictions.sort_values(by=['unique_id', 'ds'])\n",
    "df_predictions = df_predictions.set_index('unique_id')\n",
    "df_predictions = df_predictions.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>FT_RF</th>\n",
       "      <th>FT_CATBOOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>3841.781222</td>\n",
       "      <td>3801.020869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>3453.056559</td>\n",
       "      <td>3365.371782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>3732.144738</td>\n",
       "      <td>3995.492116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>4047.286764</td>\n",
       "      <td>4200.032555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>3586.662485</td>\n",
       "      <td>4420.354148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>3283.298039</td>\n",
       "      <td>2988.449150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>3091.923411</td>\n",
       "      <td>3445.189146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>3618.783522</td>\n",
       "      <td>3537.889124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>3485.080155</td>\n",
       "      <td>3964.343299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>3767.299453</td>\n",
       "      <td>3883.191105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>3741.254479</td>\n",
       "      <td>3685.598866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>3862.776600</td>\n",
       "      <td>4451.520274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds        FT_RF  FT_CATBOOST\n",
       "0          0 2023-12-31  3841.781222  3801.020869\n",
       "1          0 2024-01-31  3453.056559  3365.371782\n",
       "2          0 2024-02-29  3732.144738  3995.492116\n",
       "3          0 2024-03-31  4047.286764  4200.032555\n",
       "4          0 2024-04-30  3586.662485  4420.354148\n",
       "5          0 2024-05-31  3283.298039  2988.449150\n",
       "6          0 2024-06-30  3091.923411  3445.189146\n",
       "7          0 2024-07-31  3618.783522  3537.889124\n",
       "8          0 2024-08-31  3485.080155  3964.343299\n",
       "9          0 2024-09-30  3767.299453  3883.191105\n",
       "10         0 2024-10-31  3741.254479  3685.598866\n",
       "11         0 2024-11-30  3862.776600  4451.520274"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions[df_predictions['unique_id'] == '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>FT_RF</th>\n",
       "      <th>FT_CATBOOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11532</th>\n",
       "      <td>0</td>\n",
       "      <td>1993-12-31</td>\n",
       "      <td>6395.210</td>\n",
       "      <td>5030.733017</td>\n",
       "      <td>5110.994711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11533</th>\n",
       "      <td>0</td>\n",
       "      <td>1994-01-31</td>\n",
       "      <td>5404.700</td>\n",
       "      <td>4983.428083</td>\n",
       "      <td>5079.490550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11534</th>\n",
       "      <td>0</td>\n",
       "      <td>1994-02-28</td>\n",
       "      <td>5075.313</td>\n",
       "      <td>5053.121846</td>\n",
       "      <td>5068.426447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11535</th>\n",
       "      <td>0</td>\n",
       "      <td>1994-03-31</td>\n",
       "      <td>5584.710</td>\n",
       "      <td>5061.549357</td>\n",
       "      <td>5092.261053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11536</th>\n",
       "      <td>0</td>\n",
       "      <td>1994-04-30</td>\n",
       "      <td>4851.400</td>\n",
       "      <td>4932.246386</td>\n",
       "      <td>5048.905764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>2822.500</td>\n",
       "      <td>5511.256406</td>\n",
       "      <td>3091.247290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>4040.000</td>\n",
       "      <td>3058.784137</td>\n",
       "      <td>3994.005308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>4359.530</td>\n",
       "      <td>5096.992738</td>\n",
       "      <td>3934.854764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>4424.030</td>\n",
       "      <td>4251.046159</td>\n",
       "      <td>3811.534442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>4262.530</td>\n",
       "      <td>6426.548201</td>\n",
       "      <td>5010.353486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id         ds         y        FT_RF  FT_CATBOOST\n",
       "11532         0 1993-12-31  6395.210  5030.733017  5110.994711\n",
       "11533         0 1994-01-31  5404.700  4983.428083  5079.490550\n",
       "11534         0 1994-02-28  5075.313  5053.121846  5068.426447\n",
       "11535         0 1994-03-31  5584.710  5061.549357  5092.261053\n",
       "11536         0 1994-04-30  4851.400  4932.246386  5048.905764\n",
       "...         ...        ...       ...          ...          ...\n",
       "379           0 2023-07-31  2822.500  5511.256406  3091.247290\n",
       "380           0 2023-08-31  4040.000  3058.784137  3994.005308\n",
       "381           0 2023-09-30  4359.530  5096.992738  3934.854764\n",
       "382           0 2023-10-31  4424.030  4251.046159  3811.534442\n",
       "383           0 2023-11-30  4262.530  6426.548201  5010.353486\n",
       "\n",
       "[360 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[combined_df['unique_id'] == '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = df_predictions['unique_id'].unique()\n",
    "exp_name = f\"ADE_unico\"\n",
    "path_experiments = f'./timeseries/mestrado/resultados/{exp_name}/'\n",
    "path_csv = f\"{path_experiments}/ANP_MONTHLY.csv\"\n",
    "os.makedirs(path_experiments, exist_ok=True)\n",
    "\n",
    "cols_serie = [\"dataset_index\", \"horizon\" ,\"regressor\", \"mape\", \"pocid\", \"smape\", \"rmse\", \"msmape\", \"mae\", \"test\", \"predictions\", 'start_test', 'final_test']\n",
    "horizon = 12\n",
    "for df_index in unique_ids:\n",
    "\tdf_train_cv = combined_df[combined_df['unique_id'] == df_index]\n",
    "\t# df_train_cv = combined_df\n",
    "\tensemble_predictions = df_predictions[df_predictions['unique_id'] == df_index]\n",
    "\tmain_df = df_train_cv[['unique_id','ds', 'y']]\n",
    "\n",
    "\tfrom metaforecast.ensembles import ADE\n",
    "\tensemble = ADE(freq='ME', meta_lags=list(range(1,horizon+1)), trim_ratio=1)\n",
    "\tensemble.fit(df_train_cv)\n",
    "\tade_fcst = ensemble.predict(ensemble_predictions, train=main_df, h=horizon)\n",
    "\tfilt_test = df_svr[df_svr['dataset_index'] == int(df_index)]\n",
    "\tfilt_test = filt_test[filt_test['final_test'] == '2024-11-30']\n",
    "\ttest = extract_values(filt_test['predictions'].tolist()[0])\n",
    "\t\n",
    "\t# print(ensemble.weights)\n",
    "\t# print(ensemble._weights_by_uid(ensemble_predictions, 12))\n",
    "\t\n",
    "\tpreds_real = ade_fcst.tolist()\n",
    "\ttest = np.array(test)\n",
    "\tpreds_real_array = np.array(preds_real)\n",
    "\tpreds_real_reshaped = preds_real_array.reshape(1, -1)\n",
    "\ttest_reshaped = test.reshape(1, -1)\n",
    "\tsmape_result = calculate_smape(preds_real_reshaped, test_reshaped)\n",
    "\trmse_result = calculate_rmse(preds_real_reshaped, test_reshaped)\n",
    "\tmsmape_result = calculate_msmape(preds_real_reshaped, test_reshaped)\n",
    "\tmae_result = calculate_mae(preds_real_reshaped, test_reshaped)\n",
    "\tmape_result = mape(test, preds_real_array)\n",
    "\tpocid_result = pocid(test, preds_real_array)\n",
    "\t\n",
    "\tresult = {\n",
    "\t\t\t'dataset_index': df_index,\n",
    "\t\t\t'horizon': horizon,\n",
    "\t\t\t'regressor': exp_name,\n",
    "\t\t\t'mape': mape_result,\n",
    "\t\t\t'pocid': pocid_result,\n",
    "\t\t\t'smape': smape_result,\n",
    "\t\t\t'rmse': rmse_result,\n",
    "\t\t\t'msmape': msmape_result,\n",
    "\t\t\t'mae': mae_result,\n",
    "\t\t\t'test': [test.tolist()],\n",
    "\t\t\t'predictions': [ade_fcst.tolist()],\n",
    "\t\t\t'start_test': filt_test['start_test'].iloc[0],\n",
    "\t\t\t'final_test': filt_test['final_test'].iloc[0]\n",
    "\t\t}\n",
    " \n",
    "\tif not os.path.exists(path_csv):\n",
    "\t\tpd.DataFrame(columns=cols_serie).to_csv(path_csv, sep=';', index=False)\n",
    "\n",
    "\tdf_new = pd.DataFrame(result)\n",
    "\tdf_new.to_csv(path_csv, sep=';', mode='a', header=False, index=False)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
