{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/lucas/lib/python3.11/site-packages/optuna/study/_optimize.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from optuna import progress_bar as pbar_module\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from all_functions import *\n",
    "from darts import TimeSeries\n",
    "import os\n",
    "from darts.models import StatsForecastAutoETS\n",
    "from darts.models import StatsForecastAutoARIMA\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.exponential_smoothing.ets import ETSModel\n",
    "def percorrer_csv(diretorios, save_dir='./', horizon=5):\n",
    "    cont = 0\n",
    "    \n",
    "    resultado_file = save_dir+'/result_ets.csv'\n",
    "    train = pd.Series()\n",
    "    for diretorio in diretorios.split():\n",
    "        if os.path.isdir(diretorio):\n",
    "            for root, _, arquivos in os.walk(diretorio):\n",
    "                for arquivo in arquivos:\n",
    "                    if arquivo.endswith('.csv'):\n",
    "                        caminho_arquivo = os.path.join(root, arquivo)\n",
    "                        try:\n",
    "                            paths = caminho_arquivo.split('/')\n",
    "                            file_csv = paths[-1]\n",
    "                            estado = file_csv.split('_')[2]\n",
    "                            derivado = file_csv.split('_')[3].replace('.csv', '')\n",
    "                            cidade = file_csv.split('_')[1]\n",
    "                            df = pd.read_csv(caminho_arquivo, sep=\";\")\n",
    "                            df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y')\n",
    "\n",
    "                            df.set_index('timestamp', inplace=True)\n",
    "                            start_timestamp = '1998-01-01'  # ou qualquer data inicial que você queira\n",
    "                            index_series = pd.date_range(start=start_timestamp, periods=len(df), freq='Y')\n",
    "                            # series = pd.Series(series_value, index=index_series)\n",
    "                            serie_m3 = pd.Series(df['m3'].values, index=index_series)\n",
    "                            train, test = train_test_stats(serie_m3, horizon)\n",
    "                            w = len(train)\n",
    "                            # train_tf, _, _ = rolling_window_series(train, horizon)\n",
    "                            train_tf = znorm(train)\n",
    "                            train_darts = TimeSeries.from_series(train_tf)\n",
    "                            \n",
    "                            if len(serie_m3) > 12:\n",
    "                                test_index = test\n",
    "                                #roda 5 vezes para 5 anos\n",
    "                                preds_final = []\n",
    "                                preds_series = pd.Series()\n",
    "                                train_concat = train\n",
    "                                # model = StatsForecastAutoETS(model='AAN')\n",
    "                                # model = StatsForecastAutoARIMA(season_length=1)\n",
    "                                model = ETSModel(train_tf, trend='add', damped_trend=True, seasonal_periods=1, freq='A').fit(full_output=False, disp=False)\n",
    "\n",
    "\n",
    "                                predictions = model.forecast(steps=horizon)\n",
    "                                preds_norm = pd.Series(predictions, index=test.index)\n",
    "                                # model.fit(train_darts)\n",
    "                                # result = model.predict(n=horizon)\n",
    "                                # preds_norm = pd.Series(result.values().flatten().tolist(), index=test.index)\n",
    "                                preds_real = reverse_transform_norm_preds(preds_norm, train_concat, \"normal\", w=horizon)\n",
    "                                preds_final = preds_real.values\n",
    "                                # for i in range(5):\n",
    "                                #     model = StatsForecastAutoETS()\n",
    "                                #     model.fit(train_darts)\n",
    "                                #     result = model.predict(n=1)\n",
    "                                #     new_index = test_index.index[0] + pd.DateOffset(years=i)\n",
    "                                #     new_index = pd.DatetimeIndex([new_index])\n",
    "                                #     preds_norm = pd.Series(result.values().flatten().tolist(), index=new_index)\n",
    "                                #     w = len(train_concat)\n",
    "                                #     preds_real = reverse_transform_norm_preds(preds_norm, train_concat, \"normal\", w=w)\n",
    "                                #     train_concat = pd.concat([train_concat, preds_real])\n",
    "                                #     preds_final.extend(preds_real.values)\n",
    "                                #     if preds_series.empty:\n",
    "                                #         preds_series = preds_real\n",
    "                                #     else:\n",
    "                                #         preds_series = pd.concat([preds_series, preds_real])\n",
    "                                    \n",
    "                                #     #concat train com preds_real\n",
    "                                #     # train_concat_tf, _, _ = rolling_window_series(train_concat, w)\n",
    "                                #     train_concat_tf = znorm(train_concat)\n",
    "                                #     train_darts = TimeSeries.from_series(train_concat_tf)\n",
    "                                    \n",
    "                                cont+=1\n",
    "                                mape_result = mape(test.values, preds_final)\n",
    "                                pocid_result = pocid(test.values, preds_final)\n",
    "                                dados = {\n",
    "                                    'PRODUCT': derivado,\n",
    "                                    'UF': estado.upper(),\n",
    "                                    'MODEL': 'ETS',\n",
    "                                    'PARAMETERS': str({'trend':'add', 'damped_trend':True, 'seasonal_periods':1, 'freq':'A'}),\n",
    "                                    # 'mape': mape_result,\n",
    "                                    # 'pocid': pocid_result,\n",
    "                                    'city': cidade,\n",
    "                                    'test': [list(test.values)],\n",
    "                                    'preds': [list(preds_final)],\n",
    "                                    # 'index_test': [test.index],\n",
    "                                    # 'index_preds': [preds_series.index]\n",
    "                                    \n",
    "                                }\n",
    "                                df_result = pd.DataFrame(dados)\n",
    "                                df_result = df_result.reset_index(drop=True)\n",
    "                                print(cont)\n",
    "\n",
    "                                if not os.path.exists(resultado_file):\n",
    "                                    df_result.to_csv(resultado_file, sep=';', index=False, mode='w', header=True)\n",
    "                                else:\n",
    "                                    df_result.to_csv(resultado_file, sep=';', index=False, mode='a', header=False)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Erro ao ler {arquivo}: {e}\")\n",
    "        else:\n",
    "            print(train)\n",
    "            print(f\"O diretório {diretorio} não existe ou não é uma pasta válida.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_name</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>end_timestamp</th>\n",
       "      <th>state_code</th>\n",
       "      <th>product</th>\n",
       "      <th>series_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>MA</td>\n",
       "      <td>ethanol</td>\n",
       "      <td>[7578.939, 11475.757, 6385.067, 10140.217, 594...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>PI</td>\n",
       "      <td>fuel oil</td>\n",
       "      <td>[332.7479592, 168.6918367, 109.4561224, 227.63...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>PE</td>\n",
       "      <td>gasoline-a</td>\n",
       "      <td>[174.962, 174.962, 151.817, 130.48, 146.045, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>ES</td>\n",
       "      <td>gasoline-a</td>\n",
       "      <td>[72.757, 22.008, 28.185, 8.538, 46.206, 19.085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>SC</td>\n",
       "      <td>ethanol</td>\n",
       "      <td>[40668.734, 32451.235, 30350.948, 36121.386, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>T212</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>PR</td>\n",
       "      <td>diesel</td>\n",
       "      <td>[153548.404, 144427.716, 171067.003, 234172.8,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>T213</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>AC</td>\n",
       "      <td>LPG</td>\n",
       "      <td>[1310.456522, 1212.697464, 1268.0, 1557.637681...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>T214</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>MG</td>\n",
       "      <td>kerosene-a</td>\n",
       "      <td>[8564.399, 6235.286, 4334.646, 7481.727, 6199....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>T215</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>GO</td>\n",
       "      <td>kerosene-i</td>\n",
       "      <td>[368.413, 415.717, 420.841, 731.662, 455.111, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>T216</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>CE</td>\n",
       "      <td>kerosene-a</td>\n",
       "      <td>[9388.163, 4634.727, 2431.101, 3259.749, 3492....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    series_name start_timestamp end_timestamp state_code     product  \\\n",
       "0            T1      1990-01-01    2025-06-01         MA     ethanol   \n",
       "1            T2      1990-01-01    2025-06-01         PI    fuel oil   \n",
       "2            T3      1990-01-01    2025-06-01         PE  gasoline-a   \n",
       "3            T4      1990-01-01    2025-06-01         ES  gasoline-a   \n",
       "4            T5      1990-01-01    2025-06-01         SC     ethanol   \n",
       "..          ...             ...           ...        ...         ...   \n",
       "211        T212      1990-01-01    2025-06-01         PR      diesel   \n",
       "212        T213      1990-01-01    2025-06-01         AC         LPG   \n",
       "213        T214      1990-01-01    2025-06-01         MG  kerosene-a   \n",
       "214        T215      1990-01-01    2025-06-01         GO  kerosene-i   \n",
       "215        T216      1990-01-01    2025-06-01         CE  kerosene-a   \n",
       "\n",
       "                                          series_value  \n",
       "0    [7578.939, 11475.757, 6385.067, 10140.217, 594...  \n",
       "1    [332.7479592, 168.6918367, 109.4561224, 227.63...  \n",
       "2    [174.962, 174.962, 151.817, 130.48, 146.045, 1...  \n",
       "3    [72.757, 22.008, 28.185, 8.538, 46.206, 19.085...  \n",
       "4    [40668.734, 32451.235, 30350.948, 36121.386, 2...  \n",
       "..                                                 ...  \n",
       "211  [153548.404, 144427.716, 171067.003, 234172.8,...  \n",
       "212  [1310.456522, 1212.697464, 1268.0, 1557.637681...  \n",
       "213  [8564.399, 6235.286, 4334.646, 7481.727, 6199....  \n",
       "214  [368.413, 415.717, 420.841, 731.662, 455.111, ...  \n",
       "215  [9388.163, 4634.727, 2431.101, 3259.749, 3492....  \n",
       "\n",
       "[216 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from streamfuels.datasets import DatasetLoader\n",
    "\n",
    "loader = DatasetLoader()\n",
    "# result, flag = loader.monthly_sales_state()\n",
    "\n",
    "df, metadata = loader.read_tsf(path_tsf='./monthly_fuel_sales_by_state.tsf')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
