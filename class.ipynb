{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.datasets import (\n",
    "    load_anomaly_detection,\n",
    "    load_classification,\n",
    "    load_forecasting,\n",
    "    load_regression,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, RidgeCV, RidgeClassifierCV, RidgeClassifier\n",
    "import pywt\n",
    "from pyts.image import MarkovTransitionField\n",
    "from pyts.image import GramianAngularField\n",
    "from pyts.image import RecurrencePlot\n",
    "from aeon.transformations.detrend import ConditionalDeseasonalizer\n",
    "\n",
    "# from all_functions import *\n",
    "\n",
    "def znorm(x):\n",
    "  x_znorm = (x - np.mean(x)) / np.std(x)\n",
    "  return x_znorm\n",
    "\n",
    "\n",
    "def normalize_series_znorm(X):\n",
    "    rep = []\n",
    "    # X_train_series = X.flatten()\n",
    "\n",
    "    # transform = ConditionalDeseasonalizer(sp=12)\n",
    "    # transform.fit(X_train_series)\n",
    "    # X_train_deseasonal = transform.transform(X_train_series)\n",
    "    # X_train_flat_reshaped = X_train_deseasonal.reshape(X.shape)\n",
    "\n",
    "    X_train_flat_reshaped = X\n",
    "    for x in X_train_flat_reshaped:\n",
    "      # x_normalized = znorm(x)\n",
    "      x_normalized = x\n",
    "      rep.append(transform_series2(x_normalized, \"STFT\", \"bior2.2\", 2))\n",
    "    new = np.array(rep)\n",
    "    return new.reshape(new.shape[0], -1)\n",
    "\n",
    "def flatten_series(X):\n",
    "    return X.reshape(X.shape[0], -1)\n",
    "  \n",
    "def flatten_labels(y):\n",
    "    return np.ravel(y)\n",
    "\n",
    "def transform_series2(series, representation, wavelet, level):\n",
    "  # series = np.array(znorm(series))\n",
    "  if representation == \"CWT\":\n",
    "    coeffs, freqs = pywt.cwt(series, scales=np.arange(1, len(series) + 1), wavelet=wavelet) # morl\n",
    "    im_final = coeffs\n",
    "  elif representation == \"DWT\":\n",
    "    coeffs = pywt.wavedec(series, wavelet=wavelet, level=level)\n",
    "    im_final = np.concatenate(coeffs, axis=0) \n",
    "  elif representation == \"SWT\":\n",
    "    coeffs_swt = pywt.swt(series, wavelet, level=level)\n",
    "    im_final = np.concatenate([coeff[0] for coeff in coeffs_swt] + [coeff[1] for coeff in coeffs_swt], axis=0)\n",
    "\n",
    "  elif representation == \"WPT\":\n",
    "    wp = pywt.WaveletPacket(data=series, wavelet=wavelet, maxlevel=4, mode='symmetric')\n",
    "\n",
    "    # Extrair os coeficientes em diferentes níveis\n",
    "    nodes = wp.get_level(4, order='freq')  # Pegando o 4º nível de decomposição\n",
    "    coeffs_wpt = np.array([n.data for n in nodes])\n",
    "\n",
    "    # Concatenar os coeficientes para visualização\n",
    "    im_final = np.concatenate(coeffs_wpt, axis=0)\n",
    "  elif representation == \"STFT\":\n",
    "    from scipy.signal import stft\n",
    "    f, t, Zxx = stft(series,window='hann', nperseg=64)\n",
    "\n",
    "    # Obter a magnitude dos coeficientes\n",
    "    coeffs_stft = np.abs(Zxx)\n",
    "\n",
    "    # Concatenar os coeficientes para criar im_final\n",
    "    im_final = coeffs_stft\n",
    "    \n",
    "  elif representation == \"MTF\":\n",
    "    series = series.reshape(1, len(series))\n",
    "    mtf = MarkovTransitionField(strategy='normal') #n_bins=4, strategy='uniform'\n",
    "    X_mtf = mtf.fit_transform(series)\n",
    "    im_final = X_mtf[0]\n",
    "  elif representation == \"GADF\":\n",
    "    series = series.reshape(1, len(series))\n",
    "    gaf = GramianAngularField(method='difference')\n",
    "    X_gaf = gaf.fit_transform(series)\n",
    "    im_final = X_gaf[0]\n",
    "  elif representation == \"GASF\":\n",
    "    series = series.reshape(1, len(series))\n",
    "    gaf = GramianAngularField(method='summation')\n",
    "    X_gaf = gaf.fit_transform(series)\n",
    "    im_final = X_gaf[0]\n",
    "  elif representation == \"RP\":\n",
    "    series = series.reshape(1, len(series))\n",
    "    rp = RecurrencePlot(threshold='distance')\n",
    "    X_rp = rp.fit_transform(series)\n",
    "    im_final = X_rp[0]\n",
    "  elif representation == \"FIRTS\":\n",
    "    series = series.reshape(1, len(series))\n",
    "    mtf = MarkovTransitionField(n_bins=4, strategy='uniform')\n",
    "    X_mtf = mtf.fit_transform(series)\n",
    "    gaf = GramianAngularField(method='difference')\n",
    "    X_gaf = gaf.fit_transform(series)\n",
    "    rp = RecurrencePlot(threshold='distance')\n",
    "    X_rp = rp.fit_transform(series)\n",
    "    im_final = (X_mtf[0] + X_gaf[0] + X_rp[0]) # FIRTS é fusão entre MTF, GADF e RP (vejam o artigo que passei para vocês)\n",
    "  return im_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_ucr = [\n",
    "    'Adiac',\n",
    "    'ArrowHead',\n",
    "    'BeetleFly',\n",
    "    'HouseTwenty',\n",
    "    'Computers',\n",
    "    'FaceAll',\n",
    "    'FaceFour',\n",
    "    'FacesUCR',\n",
    "    'ShapesAll',\n",
    "    'Ham',\n",
    "    'HandOutlines',\n",
    "    'InlineSkate',\n",
    "    'Lightning2',\n",
    "    'Mallat',\n",
    "    'Meat',\n",
    "    'MoteStrain',\n",
    "    'Symbols',\n",
    "    'Lightning7',\n",
    "    'MedicalImages',\n",
    "    'Wine',\n",
    "    'WordSynonyms',\n",
    "    'Worms',\n",
    "    'Yoga',\n",
    "    'Chinatown',\n",
    "    'Crop',\n",
    "    'EthanolLevel',\n",
    "    'GestureMidAirD3',\n",
    "    'Rock'\n",
    "]\n",
    "\n",
    "rocket_acc = [\n",
    "    0.7834,\n",
    "    0.8143,\n",
    "    0.9000,\n",
    "    0.9639,\n",
    "    0.7612,\n",
    "    0.9465,\n",
    "    0.9773,\n",
    "    0.9614,\n",
    "    0.9068,\n",
    "    0.7257,\n",
    "    0.9424,\n",
    "    0.4569,\n",
    "    0.7590,\n",
    "    0.9559,\n",
    "    0.9483,\n",
    "    0.9146,\n",
    "    0.9743,\n",
    "    0.8233,\n",
    "    0.7995,\n",
    "    0.8130,\n",
    "    0.7534,\n",
    "    0.7403,\n",
    "    0.9104,\n",
    "    0.9825,\n",
    "    0.7513,\n",
    "    0.5828,\n",
    "    0.4146,\n",
    "    0.9000\n",
    "]\n",
    "from scipy import stats\n",
    "def z_test_accuracy(acc1, acc2, n1, n2, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Realiza um teste z para comparar as acurácias de dois classificadores.\n",
    "\n",
    "    Parâmetros:\n",
    "    acc1 (float): Acurácia do classificador 1 (entre 0 e 1).\n",
    "    acc2 (float): Acurácia do classificador 2 (entre 0 e 1).\n",
    "    n1 (int): Total de previsões do classificador 1.\n",
    "    n2 (int): Total de previsões do classificador 2.\n",
    "    alpha (float): Nível de significância para o teste (default: 0.05).\n",
    "\n",
    "    Retorna:\n",
    "    tuple: (valor do teste z, p-valor, str: mensagem de significância)\n",
    "    \"\"\"\n",
    "    # Proporções\n",
    "    p1 = acc1\n",
    "    p2 = acc2\n",
    "\n",
    "    # Variâncias\n",
    "    var1 = p1 * (1 - p1) / n1\n",
    "    var2 = p2 * (1 - p2) / n2\n",
    "\n",
    "    # Cálculo do z\n",
    "    z = (p1 - p2) / np.sqrt(var1 + var2)\n",
    "\n",
    "    # Cálculo do p-valor (bilateral)\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "\n",
    "    # Mensagem de significância\n",
    "    if p_value < alpha:\n",
    "        significance = \"significativa\"\n",
    "    else:\n",
    "        significance = \"não_significativa\"\n",
    "\n",
    "    return z, p_value, significance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anp/anaconda3/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:1240: UserWarning: nperseg = 64 is greater than input length  = 24, using nperseg = 24\n",
      "  freqs, time, Zxx = _spectral_helper(x, x, fs, window, nperseg, noverlap,\n",
      "/home/anp/anaconda3/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:1240: UserWarning: nperseg = 64 is greater than input length  = 46, using nperseg = 46\n",
      "  freqs, time, Zxx = _spectral_helper(x, x, fs, window, nperseg, noverlap,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "accuracies = []\n",
    "\n",
    "sigs = []\n",
    "for index, d in enumerate(datasets_ucr):\n",
    "    X, y, meta = load_classification(d, return_metadata=True)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_train_flattened = flatten_series(X_train)\n",
    "    X_test_flattened = flatten_series(X_test)\n",
    "\n",
    "    X_train_normalized = normalize_series_znorm(X_train_flattened)\n",
    "    X_test_normalized = normalize_series_znorm(X_test_flattened)\n",
    "    y_train_flattened = flatten_labels(y_train)\n",
    "    y_test_flattened = flatten_labels(y_test)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "    # clf = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.3, max_iter=100)\n",
    "\n",
    "    clf.fit(X_train_normalized, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test_normalized)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy = round(accuracy, 4)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    z, p_value, significance = z_test_accuracy(accuracy, rocket_acc[index], len(y_test), len(y_test))\n",
    "    sigs.append(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classificador</th>\n",
       "      <th>Rocket</th>\n",
       "      <th>Significativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7319</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.8143</td>\n",
       "      <td>significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9792</td>\n",
       "      <td>0.9639</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8400</td>\n",
       "      <td>0.7612</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9118</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9644</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7194</td>\n",
       "      <td>0.9068</td>\n",
       "      <td>significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6462</td>\n",
       "      <td>0.7257</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8686</td>\n",
       "      <td>0.9424</td>\n",
       "      <td>significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.7385</td>\n",
       "      <td>0.4569</td>\n",
       "      <td>significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.7568</td>\n",
       "      <td>0.7590</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.9559</td>\n",
       "      <td>significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9483</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.9346</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.7442</td>\n",
       "      <td>0.8233</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.7995</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.8130</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.6618</td>\n",
       "      <td>0.7534</td>\n",
       "      <td>significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.7403</td>\n",
       "      <td>significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.9104</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.7844</td>\n",
       "      <td>0.7513</td>\n",
       "      <td>significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.6391</td>\n",
       "      <td>0.5828</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.3431</td>\n",
       "      <td>0.4146</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>não_significativa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Classificador  Rocket      Significativo\n",
       "0          0.7319  0.7834  não_significativa\n",
       "1          0.9375  0.8143      significativa\n",
       "2          0.8333  0.9000  não_significativa\n",
       "3          0.9792  0.9639  não_significativa\n",
       "4          0.8400  0.7612  não_significativa\n",
       "5          0.9585  0.9465  não_significativa\n",
       "6          0.9118  0.9773  não_significativa\n",
       "7          0.9644  0.9614  não_significativa\n",
       "8          0.7194  0.9068      significativa\n",
       "9          0.6462  0.7257  não_significativa\n",
       "10         0.8686  0.9424      significativa\n",
       "11         0.7385  0.4569      significativa\n",
       "12         0.7568  0.7590  não_significativa\n",
       "13         0.9986  0.9559      significativa\n",
       "14         0.9444  0.9483  não_significativa\n",
       "15         0.9346  0.9146  não_significativa\n",
       "16         0.9739  0.9743  não_significativa\n",
       "17         0.7442  0.8233  não_significativa\n",
       "18         0.7930  0.7995  não_significativa\n",
       "19         0.7647  0.8130  não_significativa\n",
       "20         0.6618  0.7534      significativa\n",
       "21         0.5769  0.7403      significativa\n",
       "22         0.9081  0.9104  não_significativa\n",
       "23         0.9725  0.9825  não_significativa\n",
       "24         0.7844  0.7513      significativa\n",
       "25         0.6391  0.5828  não_significativa\n",
       "26         0.3431  0.4146  não_significativa\n",
       "27         0.8571  0.9000  não_significativa"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Classificador': accuracies,\n",
    "    'Rocket': rocket_acc,\n",
    "    'Significativo': sigs,\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nosso modelo foi igual/melhor que o Rocket 24/28.\n"
     ]
    }
   ],
   "source": [
    "def contar_classificador_melhor(df):\n",
    "    contagem = 0\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['Significativo'] == 'não_significativa':\n",
    "            contagem += 1\n",
    "        elif row['Significativo'] == 'significativa':\n",
    "            if row['Classificador'] > row['Rocket']:\n",
    "                contagem += 1\n",
    "    \n",
    "    return contagem\n",
    "\n",
    "contagem_resultado = contar_classificador_melhor(df)\n",
    "print(f\"Nosso modelo foi igual/melhor que o Rocket {contagem_resultado}/{len(accuracies)}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
