{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'aeon'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mall_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m/exp/lucas/Statistics_and_Seq2Seq/all_functions.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maeon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mforecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ARIMA\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseasonal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m seasonal_decompose\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error \u001b[38;5;28;01mas\u001b[39;00m mse\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'aeon'"
     ]
    }
   ],
   "source": [
    "from all_functions import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "window = 12\n",
    "horizon = 12\n",
    "derivado = \"gasolinac\"\n",
    "estado = \"SP\"\n",
    "# df = read_series(f'../datasets/venda/mensal/uf/{derivado}/mensal_{estado.lower()}_{derivado}.csv')\n",
    "# train, test = train_test_stats(df, horizon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device Count: 2\n",
      "Current Device: 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'gpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 88\u001b[0m\n\u001b[1;32m     72\u001b[0m lr_logger \u001b[38;5;241m=\u001b[39m LearningRateMonitor()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# from pytorch_lightning import loggers as pl_loggers\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# tensorboard = pl_loggers.TensorBoardLogger('./')\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# trainer = pl.Trainer(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m#     # logger=tensorboard\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#-1\u001b[39;49;00m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauto_lr_find\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clip_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit_train_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit_val_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#fast_dev_run=fdv_steps,\u001b[39;49;00m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#log_every_n_steps=10,\u001b[39;49;00m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# profiler=True,\u001b[39;49;00m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_logger\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;66;43;03m#, early_stop_callback],\u001b[39;49;00m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#enable_checkpointing=True,\u001b[39;49;00m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#default_root_dir=\"C:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\DeepAR-pytorch\\My_model\\2_freq_nbinom_LSTM\\1_cluster_demand_prediction\\logs\"\u001b[39;49;00m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m deepar \u001b[38;5;241m=\u001b[39m DeepAR\u001b[38;5;241m.\u001b[39mfrom_dataset(\n\u001b[1;32m    106\u001b[0m     training,\n\u001b[1;32m    107\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# reduce_on_plateau_patience=3,\u001b[39;00m\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of parameters in network: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeepar\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e3\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/deepar/lib/python3.8/site-packages/lightning/pytorch/utilities/argparse.py:70\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'gpus'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import EncoderNormalizer, GroupNormalizer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "from pytorch_forecasting.data.examples import generate_ar_data\n",
    "from pytorch_forecasting.metrics import NormalDistributionLoss\n",
    "from pytorch_forecasting.models.deepar import DeepAR\n",
    "from pytorch_forecasting.utils import profile\n",
    "\n",
    "warnings.simplefilter(\"error\", category=SettingWithCopyWarning)\n",
    "\n",
    "\n",
    "data = generate_ar_data(seasonality=10.0, timesteps=400, n_series=100)\n",
    "data[\"static\"] = \"2\"\n",
    "data[\"date\"] = pd.Timestamp(\"2020-01-01\") + pd.to_timedelta(data.time_idx, \"D\")\n",
    "validation = data.series.sample(20)\n",
    "\n",
    "max_encoder_length = 60\n",
    "max_prediction_length = 20\n",
    "\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: ~x.series.isin(validation)],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"value\",\n",
    "    categorical_encoders={\"series\": NaNLabelEncoder().fit(data.series)},\n",
    "    group_ids=[\"series\"],\n",
    "    static_categoricals=[\"static\"],\n",
    "    min_encoder_length=max_encoder_length,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=max_prediction_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_unknown_reals=[\"value\"],\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    target_normalizer=GroupNormalizer(groups=[\"series\"]),\n",
    "    add_relative_time_idx=False,\n",
    "    add_target_scales=True,\n",
    "    randomize_length=None,\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(\n",
    "    training,\n",
    "    data[lambda x: x.series.isin(validation)],\n",
    "    # predict=True,\n",
    "    stop_randomization=True,\n",
    ")\n",
    "batch_size = 64\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "# save datasets\n",
    "training.save(\"training.pkl\")\n",
    "validation.save(\"validation.pkl\")\n",
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Device Count:\", torch.cuda.device_count())\n",
    "print(\"Current Device:\", torch.cuda.current_device())\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=5, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()\n",
    "# from pytorch_lightning import loggers as pl_loggers\n",
    "# tensorboard = pl_loggers.TensorBoardLogger('./')\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,\n",
    "    limit_val_batches=3,\n",
    "    # fast_dev_run=True,\n",
    "    # logger=logger,\n",
    "    # profiler=True,\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    # logger=tensorboard\n",
    ")\n",
    "\n",
    "\n",
    "deepar = DeepAR.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.1,\n",
    "    hidden_size=32,\n",
    "    dropout=0.1,\n",
    "    loss=NormalDistributionLoss(),\n",
    "    log_interval=10,\n",
    "    log_val_interval=3,\n",
    "    # reduce_on_plateau_patience=3,\n",
    ")\n",
    "print(f\"Number of parameters in network: {deepar.size()/1e3:.1f}k\")\n",
    "\n",
    "# # find optimal learning rate\n",
    "# deepar.hparams.log_interval = -1\n",
    "# deepar.hparams.log_val_interval = -1\n",
    "# trainer.limit_train_batches = 1.0\n",
    "# res = Tuner(trainer).lr_find(\n",
    "#     deepar, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader, min_lr=1e-5, max_lr=1e2\n",
    "# )\n",
    "\n",
    "# print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "# fig = res.plot(show=True, suggest=True)\n",
    "# fig.show()\n",
    "# deepar.hparams.learning_rate = res.suggestion()\n",
    "\n",
    "torch.set_num_threads(10)\n",
    "trainer.fit(\n",
    "    deepar,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n",
    "\n",
    "# calcualte mean absolute error on validation set\n",
    "# actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "# predictions = deepar.predict(val_dataloader)\n",
    "# print(f\"Mean absolute error of model: {(actuals - predictions).abs().mean()}\")\n",
    "\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "predictions = deepar.predict(val_dataloader)\n",
    "\n",
    "# Mover ambos os tensores para a GPU, se estiverem na CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "actuals = actuals.to(device)\n",
    "predictions = predictions.to(device)\n",
    "\n",
    "# Calcular e exibir o erro absoluto médio\n",
    "mae = (actuals - predictions).abs().mean()\n",
    "print(f\"Mean absolute error of model: {mae.item()}\")\n",
    "\n",
    "# # plot actual vs. predictions\n",
    "# raw_predictions, x = deepar.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "# for idx in range(10):  # plot 10 examples\n",
    "#     deepar.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
