{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U aeon\n",
    "#!pip install aeon[all_extras]\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from aeon.visualisation import plot_series\n",
    "from all_functions import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from aeon.transformations.detrend import STLTransformer\n",
    "import ast\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import os\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from datetime import datetime\n",
    "from distutils.util import strtobool\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "def convert_to_list(series_str):\n",
    "    return eval(series_str)\n",
    "\n",
    "def get_preds_hybrid(path, test_date, start_index):\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    results = {}\n",
    "    filtered_df = df[df['test_range'] == test_date]\n",
    "    columns_p1_to_p12 = filtered_df.loc[:, 'P1':'P12']\n",
    "    values_list = columns_p1_to_p12.values.flatten().tolist()     \n",
    "    results = pd.Series(values_list, index=start_index)\n",
    "    return results\n",
    "\n",
    "def generate_index(start_date, end_date):\n",
    "    end_date_dt = pd.to_datetime(end_date)\n",
    "    \n",
    "    start_date_dt = pd.to_datetime(start_date)\n",
    "    \n",
    "    index = pd.period_range(start=start_date_dt, end=end_date_dt, freq='M')\n",
    "\n",
    "    return index\n",
    "\n",
    "def get_each_point_error(path, val_date):\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    \n",
    "    df_filtered = df[df['test_range'] <= val_date].copy()\n",
    "\n",
    "    df_filtered = df_filtered.iloc[::-1]\n",
    "    \n",
    "    error_series_concatenated = []\n",
    "    for _, row in df_filtered.iterrows():\n",
    "        error_series_str = row['error_series']\n",
    "        error_list = ast.literal_eval(error_series_str)\n",
    "        error_series_concatenated.append(error_list)\n",
    "    return error_series_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [\"ETS\",\"catboost\", \"arima\", \"rf\"]\n",
    "# transformations = [\"normal\", \"deseasonal\"]\n",
    "from dtaidistance import dtw\n",
    "from scipy.stats import norm\n",
    "from tslearn.barycenters import \\\n",
    "    euclidean_barycenter, \\\n",
    "    dtw_barycenter_averaging, \\\n",
    "    dtw_barycenter_averaging_subgradient, \\\n",
    "    softdtw_barycenter\n",
    "\n",
    "from aeon.clustering.averaging import elastic_barycenter_average\n",
    "from minisom import MiniSom\n",
    "dirs = [\n",
    "    '../datasets/venda/mensal/uf/gasolinac/',\n",
    "    '../datasets/venda/mensal/uf/etanolhidratado/',\n",
    "    '../datasets/venda/mensal/uf/glp/',\n",
    "    '../datasets/venda/mensal/uf/oleodiesel/',\n",
    "    '../datasets/venda/mensal/uf/querosenedeaviacao/',\n",
    "]\n",
    "horizon = 12\n",
    "window = 12\n",
    "model_transformation = [\n",
    "                        \"GASF_ridge_deseasonal\",\n",
    "                        \"GADF_ridge_deseasonal\",\n",
    "                        \"STFT_ridge_deseasonal\",\n",
    "                        \"MTF_ridge_deseasonal\",\n",
    "                        \"RP_ridge_deseasonal\",\n",
    "                        \"FIRTS_ridge_deseasonal\",\n",
    "                        \"DWT_ridge_deseasonal\",\n",
    "                        \"SWT_ridge_deseasonal\",\n",
    "                        \"CWT_ridge_deseasonal\",\n",
    "                        \"ETS_normal\",\n",
    "                        \"WPT_ridge_deseasonal\",\n",
    "                        \"catboost_deseasonal\",\n",
    "                        \"ridge_deseasonal\",\n",
    "                        \"arima_deseasonal\"\n",
    "                        ]\n",
    "dates = [\n",
    "        # '1993-03_1994-02',\n",
    "        # '1994-03_1995-02', '1995-03_1996-02', '1996-03_1997-02', '1997-03_1998-02', '1998-03_1999-02',\n",
    "        # '1999-03_2000-02', '2000-03_2001-02', '2001-03_2002-02', '2002-03_2003-02', '2003-03_2004-02',\n",
    "        # '2004-03_2005-02', '2005-03_2006-02', '2006-03_2007-02', '2007-03_2008-02', '2008-03_2009-02',\n",
    "        # '2009-03_2010-02', '2010-03_2011-02', '2011-03_2012-02', '2012-03_2013-02', '2013-03_2014-02',\n",
    "        # '2014-03_2015-02', '2015-03_2016-02', '2016-03_2017-02', '2017-03_2018-02', '2018-03_2019-02',\n",
    "        '2019-03_2020-02', '2020-03_2021-02', '2021-03_2022-02', '2022-03_2023-02', '2023-03_2024-02',\n",
    "         ]\n",
    "\n",
    "\n",
    "date_past = {\n",
    "            '2019-03_2020-02': '2018-03_2019-02',\n",
    "            '2020-03_2021-02': '2019-03_2020-02',\n",
    "            '2021-03_2022-02': '2020-03_2021-02',\n",
    "            '2022-03_2023-02': '2021-03_2022-02',\n",
    "            '2023-03_2024-02': '2022-03_2023-02',\n",
    "             }\n",
    "\n",
    "produto = \"gasolinac\"\n",
    "estado = \"SP\"\n",
    "\n",
    "combination_format = \"som\"\n",
    "for directory in dirs:\n",
    "    all_rmse = []\n",
    "    all_pocid = []\n",
    "    all_mape = []\n",
    "    all_pbe = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.csv'):\n",
    "            uf = file.split(\"_\")[1].upper()\n",
    "            derivado = file.split(\"_\")[2].split(\".\")[0]\n",
    "            \n",
    "            # if uf == estado and produto == derivado:\n",
    "            full_path = os.path.join(directory, file)\n",
    "            series = read_series(full_path)\n",
    "            \n",
    "            all_preds_dates = []\n",
    "            all_test = []\n",
    "\n",
    "\n",
    "            for date in dates:\n",
    "                start_date, end_date = date.split('_')\n",
    "                test_index = generate_index(start_date, end_date)\n",
    "                test_real = get_test_real(series, start_date, end_date)\n",
    "                row_data = []\n",
    "                all_preds_year = []\n",
    "\n",
    "                preds_barycenter = []\n",
    "                preds_elastic = []\n",
    "                \n",
    "                for mt in model_transformation:\n",
    "                    model, transform = mt.rsplit(\"_\", 1)\n",
    "\n",
    "                    path_result = f'./paper_roma/{model}/{derivado}/{transform}/transform_{uf}.csv'\n",
    "\n",
    "                    serie_pred = get_preds_hybrid(path_result, date, test_index)\n",
    "\n",
    "                    #com base no erro\n",
    "                    # error_past = get_each_point_error(path_result, date_past[date])[0]\n",
    "                    # mean_error = abs(sum(error_past) / len(error_past))\n",
    "                    # mean_error = abs(np.mean(error_past))\n",
    "                    # std_error = np.std(error_past)\n",
    "\n",
    "                    # lower = [pred - mean_error for pred in serie_pred.tolist()]\n",
    "                    # upper = [pred + mean_error for pred in serie_pred.tolist()]\n",
    "                    # lower_mean = [pred - mean_error for pred in serie_pred]\n",
    "                    # upper_mean = [pred + mean_error for pred in serie_pred]\n",
    "\n",
    "                    # z = norm.ppf(0.95)\n",
    "                    # lower = [pred - z * std_error for pred in serie_pred]\n",
    "                    # upper = [pred + z * std_error for pred in serie_pred]\n",
    "\n",
    "\n",
    "                    # lower_upper = [lower, upper]\n",
    "                    # result_lower_upper = dtw_barycenter_averaging_subgradient(lower_upper, max_iter=35)\n",
    "                    # result_lower_upper = result_lower_upper.flatten().tolist()\n",
    "                    # preds_barycenter.append(result_lower_upper)\n",
    "                    # all_preds_year.append(result_lower_upper)\n",
    "\n",
    "                    # preds_barycenter.append(upper)\n",
    "                    # preds_barycenter.append(lower)\n",
    "\n",
    "                    # all_preds_year.append(upper)\n",
    "                    # all_preds_year.append(lower)\n",
    "\n",
    "                    # adiciona 10% para intervalo de confianca\n",
    "                    # alpha = 0.1\n",
    "                    # lower = [p - alpha * p for p in serie_pred.tolist()]\n",
    "                    # upper = [p + alpha * p for p in serie_pred.tolist()]\n",
    "\n",
    "                    # print(mt)\n",
    "                    # print(upper)\n",
    "                    # print(serie_pred.tolist())\n",
    "                    # print(lower)\n",
    "                    # print(\"--------\")\n",
    "\n",
    "\n",
    "                    \n",
    "                    # print(serie_pred)\n",
    "                    all_preds_year.append(serie_pred.tolist())\n",
    "                    \n",
    "\n",
    "                    preds_barycenter.append(serie_pred.tolist())\n",
    "                    \n",
    "                    preds_elastic.append(np.array([[serie_pred.tolist()]]))\n",
    "                    \n",
    "                    # preds_elastic.append(np.array([[lower]]))\n",
    "                    # preds_elastic.append(np.array([[upper]]))\n",
    "                    # preds_elastic.append(np.array([[result_lower_upper]]))\n",
    "                    # preds_elastic.append(np.array([[serie_pred.values]]))\n",
    "                \n",
    "                all_test.extend(test_real)\n",
    "                \n",
    "                if combination_format == \"mean\":\n",
    "                    mean_preds_year = np.mean(np.array(all_preds_year), axis=0)\n",
    "                elif combination_format == \"median\":\n",
    "                    mean_preds_year = np.median(np.array(all_preds_year), axis=0)\n",
    "                elif combination_format == \"softdtw\":\n",
    "                    #softdtw barycenter\n",
    "                    softdtw_preds = softdtw_barycenter(preds_barycenter, max_iter=35, gamma=0.01)\n",
    "                    mean_preds_year = softdtw_preds.flatten().tolist()\n",
    "                elif combination_format == \"dtw_subgradient\":\n",
    "                    #dtw avg barycenter subradient\n",
    "                    preds_dtw_subgradient = dtw_barycenter_averaging_subgradient(preds_barycenter, max_iter=35, random_state=0)\n",
    "                    mean_preds_year = preds_dtw_subgradient.flatten().tolist()\n",
    "\n",
    "                elif combination_format == \"dtw_subgradient2\":\n",
    "                    #dtw avg barycenter subradient\n",
    "                    metric_params = {\n",
    "                                        \"global_constraint\": \"itakura\",\n",
    "                                        \"sakoe_chiba_radius\": 6, \n",
    "                                        \"itakura_max_slope\": 1.5\n",
    "                                    }\n",
    "                    \n",
    "                    # init = np.median(np.array(all_preds_year), axis=0)\n",
    "                    # init = init.reshape(1, -1).T\n",
    "                    shape = 'normal'\n",
    "                    init = None\n",
    "                    X = np.array(preds_barycenter).reshape((len(preds_barycenter)), len(preds_barycenter[0]), 1)\n",
    "                    \n",
    "                    preds_dtw_subgradient = dtw_barycenter_averaging_subgradient(X, init_barycenter=init, max_iter=35, random_state=0, metric_params=metric_params)\n",
    "                    mean_preds_year = preds_dtw_subgradient.flatten().tolist()\n",
    "\n",
    "\n",
    "                elif combination_format == \"dtw\":\n",
    "                    #dtw barycenter averaging\n",
    "                    preds_dtw_avg = dtw_barycenter_averaging(preds_barycenter, max_iter=35)\n",
    "                    mean_preds_year = preds_dtw_avg.flatten().tolist()\n",
    "                \n",
    "                elif combination_format == \"eba\":\n",
    "                    #elastic barycenter average\n",
    "                    capt = np.vstack(preds_elastic)\n",
    "                    shape = \"twe\"\n",
    "                    # X = np.array(preds_elastic).reshape(len(preds_elastic), 1, 12)\n",
    "                    # init = np.median(np.array(all_preds_year), axis=0)\n",
    "                    # init = init.reshape(1, -1)\n",
    "                    init = 'random'\n",
    "                    elastic = elastic_barycenter_average(capt, distance=shape, init_barycenter=init, random_state=0),\n",
    "                    mean_preds_year = elastic[0].tolist()[0]\n",
    "                elif combination_format == \"som\":\n",
    "                    all_preds_year = np.array(all_preds_year)\n",
    "                    shape = 'mean'\n",
    "                    som_width, som_height = 2, 2\n",
    "                    som = MiniSom(som_width, som_height, input_len=all_preds_year.shape[1], sigma=0.8, learning_rate=0.3, random_seed=0)\n",
    "                    som.random_weights_init(all_preds_year)\n",
    "                    som.train_random(all_preds_year, 200)\n",
    "                    bmu_indices = np.array([som.winner(x) for x in all_preds_year])\n",
    "\n",
    "                    final_prediction = []\n",
    "                    for i in range(all_preds_year.shape[1]):\n",
    "                        cluster_means = []\n",
    "                        for x, y in np.unique(bmu_indices, axis=0):\n",
    "                            cluster_data = all_preds_year[(bmu_indices[:, 0] == x) & (bmu_indices[:, 1] == y), i]\n",
    "                            if len(cluster_data) > 0:\n",
    "                                cluster_means.append(cluster_data.mean())\n",
    "                        final_prediction.append(np.mean(cluster_means)) \n",
    "                    mean_preds_year = final_prediction\n",
    "                all_preds_dates.extend(mean_preds_year)\n",
    "\n",
    "            rmse_result = rmse(all_test, all_preds_dates)\n",
    "            mape_result = mape(all_test, all_preds_dates)\n",
    "            pocid_result = pocid(all_test, all_preds_dates)\n",
    "            pbe_result = pbe(pd.Series(all_test), pd.Series(all_preds_dates))\n",
    "            mcpm_result = mcpm(rmse_result, mape_result, pocid_result)\n",
    "\n",
    "            all_pocid.append(pocid_result)\n",
    "            all_pbe.append(pbe_result)\n",
    "            all_rmse.append(rmse_result)\n",
    "            all_mape.append(mape_result)\n",
    "        \n",
    "    \n",
    "\n",
    "    if len(all_rmse) > 0:\n",
    "        media_rmse = sum(all_rmse) / len(all_rmse)\n",
    "        media_mape = sum(all_mape) / len(all_mape)\n",
    "        media_pocid = sum(all_pocid) / len(all_pocid)\n",
    "        media_pbe = sum(all_pbe) / len(all_pbe)\n",
    "\n",
    "        representacao = f'{combination_format}_{shape}'\n",
    "\n",
    "        data = {\n",
    "            \"representacao\": [representacao],\n",
    "            \"RMSE\": [media_rmse],\n",
    "            \"MAPE\": [media_mape],\n",
    "            \"POCID\": [media_pocid],\n",
    "            \"PBE\": [media_pbe],\n",
    "            \"derivado\": [derivado]\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        csv_file = f'./metrics2/{derivado}.csv'\n",
    "        os.makedirs('./metrics2/', exist_ok=True)\n",
    "\n",
    "        df.to_csv(csv_file, mode='a', header=not pd.io.common.file_exists(csv_file), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
