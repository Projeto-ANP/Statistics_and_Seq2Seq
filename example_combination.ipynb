{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/lucas/lib/python3.11/site-packages/rapids_dask_dependency/dask_loader.py:36: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 11.0.0. Please consider upgrading.\n",
      "  mod = importlib.import_module(spec.name)\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U aeon\n",
    "#!pip install aeon[all_extras]\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from aeon.visualisation import plot_series\n",
    "from all_functions import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from aeon.transformations.detrend import STLTransformer\n",
    "import ast\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import os\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from datetime import datetime\n",
    "from distutils.util import strtobool\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "def convert_to_list(series_str):\n",
    "    return eval(series_str)\n",
    "\n",
    "def get_preds_hybrid(path, test_date, start_index):\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    results = {}\n",
    "    filtered_df = df[df['test_range'] == test_date]\n",
    "    columns_p1_to_p12 = filtered_df.loc[:, 'P1':'P12']\n",
    "    values_list = columns_p1_to_p12.values.flatten().tolist()     \n",
    "    results = pd.Series(values_list, index=start_index)\n",
    "    return results\n",
    "\n",
    "def generate_index(start_date, end_date):\n",
    "    end_date_dt = pd.to_datetime(end_date)\n",
    "    \n",
    "    start_date_dt = pd.to_datetime(start_date)\n",
    "    \n",
    "    index = pd.period_range(start=start_date_dt, end=end_date_dt, freq='M')\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [\"ETS\",\"catboost\", \"arima\", \"rf\"]\n",
    "# transformations = [\"normal\", \"deseasonal\"]\n",
    "from dtaidistance import dtw\n",
    "from tslearn.barycenters import \\\n",
    "    euclidean_barycenter, \\\n",
    "    dtw_barycenter_averaging, \\\n",
    "    dtw_barycenter_averaging_subgradient, \\\n",
    "    softdtw_barycenter\n",
    "\n",
    "from aeon.clustering.averaging import elastic_barycenter_average\n",
    "dirs = [\n",
    "    '../datasets/venda/mensal/uf/gasolinac/',\n",
    "    '../datasets/venda/mensal/uf/etanolhidratado/',\n",
    "    '../datasets/venda/mensal/uf/glp/',\n",
    "    '../datasets/venda/mensal/uf/oleodiesel/',\n",
    "]\n",
    "horizon = 12\n",
    "window = 12\n",
    "model_transformation = [\n",
    "                        \"GASF_ridge_deseasonal\",\n",
    "                        \"GADF_ridge_deseasonal\",\n",
    "                        \"STFT_ridge_deseasonal\",\n",
    "                        \"MTF_ridge_deseasonal\",\n",
    "                        \"RP_ridge_deseasonal\",\n",
    "                        \"FIRTS_ridge_deseasonal\",\n",
    "                        \"DWT_ridge_deseasonal\",\n",
    "                        \"SWT_ridge_deseasonal\",\n",
    "                        \"CWT_ridge_deseasonal\",\n",
    "                        \"ETS_normal\",\n",
    "                        \"WPT_ridge_deseasonal\",\n",
    "                        \"catboost_deseasonal\",\n",
    "                        \"ridge_deseasonal\",\n",
    "                        \"arima_deseasonal\"\n",
    "                        ]\n",
    "dates = [\n",
    "        # '1993-03_1994-02',\n",
    "        # '1994-03_1995-02', '1995-03_1996-02', '1996-03_1997-02', '1997-03_1998-02', '1998-03_1999-02',\n",
    "        # '1999-03_2000-02', '2000-03_2001-02', '2001-03_2002-02', '2002-03_2003-02', '2003-03_2004-02',\n",
    "        # '2004-03_2005-02', '2005-03_2006-02', '2006-03_2007-02', '2007-03_2008-02', '2008-03_2009-02',\n",
    "        # '2009-03_2010-02', '2010-03_2011-02', '2011-03_2012-02', '2012-03_2013-02', '2013-03_2014-02',\n",
    "        # '2014-03_2015-02', '2015-03_2016-02', '2016-03_2017-02', '2017-03_2018-02', '2018-03_2019-02',\n",
    "        '2019-03_2020-02', '2020-03_2021-02', '2021-03_2022-02', '2022-03_2023-02', '2023-03_2024-02',\n",
    "         ]\n",
    "\n",
    "produto = \"gasolinac\"\n",
    "estado = \"SP\"\n",
    "\n",
    "combination_format = \"twe\"\n",
    "for directory in dirs:\n",
    "    all_rmse = []\n",
    "    all_pocid = []\n",
    "    all_mape = []\n",
    "    all_pbe = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.csv'):\n",
    "            uf = file.split(\"_\")[1].upper()\n",
    "            derivado = file.split(\"_\")[2].split(\".\")[0]\n",
    "            \n",
    "            # if uf == estado and produto == derivado:\n",
    "            full_path = os.path.join(directory, file)\n",
    "            series = read_series(full_path)\n",
    "            \n",
    "            all_preds_dates = []\n",
    "            all_test = []\n",
    "\n",
    "\n",
    "            for date in dates:\n",
    "                start_date, end_date = date.split('_')\n",
    "                test_index = generate_index(start_date, end_date)\n",
    "                test_real = get_test_real(series, start_date, end_date)\n",
    "                row_data = []\n",
    "                all_preds_year = []\n",
    "\n",
    "                preds_barycenter = []\n",
    "                preds_elastic = []\n",
    "                \n",
    "                for mt in model_transformation:\n",
    "                    model, transform = mt.rsplit(\"_\", 1)\n",
    "                    \n",
    "                    serie_pred = get_preds_hybrid(f'./paper_roma/{model}/{derivado}/{transform}/transform_{uf}.csv', date, test_index)\n",
    "                    # print(serie_pred)\n",
    "                    all_preds_year.append(serie_pred.tolist())\n",
    "\n",
    "                    preds_barycenter.append(serie_pred.tolist())\n",
    "                    \n",
    "                    preds_elastic.append(np.array([[serie_pred.tolist()]]))\n",
    "                    # preds_elastic.append(np.array([[serie_pred.values]]))\n",
    "                \n",
    "                all_test.extend(test_real)\n",
    "                \n",
    "                # mean_preds_year = np.mean(np.array(all_preds_year), axis=0)\n",
    "                # mean_preds_year = np.median(np.array(all_preds_year), axis=0)\n",
    "\n",
    "                if combination_format == \"softdtw\":\n",
    "                    #softdtw barycenter\n",
    "                    softdtw_preds = softdtw_barycenter(preds_barycenter, max_iter=35, gamma=0.01)\n",
    "                    mean_preds_year = softdtw_preds.flatten().tolist()\n",
    "                elif combination_format == \"dtw_subgradient\":\n",
    "                    #dtw avg barycenter subradient\n",
    "                    preds_dtw_subgradient = dtw_barycenter_averaging_subgradient(preds_barycenter, max_iter=35)\n",
    "                    mean_preds_year = preds_dtw_subgradient.flatten().tolist()\n",
    "\n",
    "\n",
    "                elif combination_format == \"dtw\":\n",
    "                    #dtw barycenter averaging\n",
    "                    preds_dtw_avg = dtw_barycenter_averaging(preds_barycenter, max_iter=35)\n",
    "                    mean_preds_year = preds_dtw_avg.flatten().tolist()\n",
    "                \n",
    "                elif combination_format == \"twe\":\n",
    "                    #elastic barycenter average\n",
    "                    capt = np.vstack(preds_elastic)\n",
    "                    elastic = elastic_barycenter_average(capt, distance=\"twe\", reach=15),\n",
    "                    mean_preds_year = elastic[0].tolist()[0]\n",
    "\n",
    "                all_preds_dates.extend(mean_preds_year)\n",
    "\n",
    "            rmse_result = rmse(all_test, all_preds_dates)\n",
    "            mape_result = mape(all_test, all_preds_dates)\n",
    "            pocid_result = pocid(all_test, all_preds_dates)\n",
    "            pbe_result = pbe(pd.Series(all_test), pd.Series(all_preds_dates))\n",
    "            mcpm_result = mcpm(rmse_result, mape_result, pocid_result)\n",
    "\n",
    "            all_pocid.append(pocid_result)\n",
    "            all_pbe.append(pbe_result)\n",
    "            all_rmse.append(rmse_result)\n",
    "            all_mape.append(mape_result)\n",
    "        \n",
    "    \n",
    "\n",
    "    if len(all_rmse) > 0:\n",
    "        media_rmse = sum(all_rmse) / len(all_rmse)\n",
    "        media_mape = sum(all_mape) / len(all_mape)\n",
    "        media_pocid = sum(all_pocid) / len(all_pocid)\n",
    "        media_pbe = sum(all_pbe) / len(all_pbe)\n",
    "\n",
    "        representacao = combination_format\n",
    "\n",
    "        data = {\n",
    "            \"representacao\": [representacao],\n",
    "            \"RMSE\": [media_rmse],\n",
    "            \"MAPE\": [media_mape],\n",
    "            \"POCID\": [media_pocid],\n",
    "            \"PBE\": [media_pbe],\n",
    "            \"derivado\": [derivado]\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        csv_file = f'{derivado}.csv'\n",
    "\n",
    "        df.to_csv(csv_file, mode='a', header=not pd.io.common.file_exists(csv_file), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
